:PROPERTIES:
:ID:       db3694d3-01ed-4a3c-ba6b-74190b348e6d
:ROAM_ALIASES: RNDL
:END:
#+title: Reti Neurali & Deep Learning
#+filetags: university master ai
#+date: [2022-09-22 Thu 19:16]
- Prof.essa Valentina Gliozzi, Prof.essa Rossella Cancelliere
- https://transno.com/doc/3y-nWb7O0Jl

* Principi
- le reti neurali sono strutture che simulano il comportamento del cervello umano
  - in particolare l'unita' base: il *neurone*
    - funzioni: /raccoglie, elabora, propaga/ segnali

La struttura in particolare e' composta da diverse parti:
1. neuroni di *input*
2. neurone di *output*
   - a questo e' associato un ulteriore input: il *bias*
     - la tendenza ad attivarsi
3. la somma *pesata* viene passata a una *funzione di attivazione*, da questa deriva il risultato

Una *rete neurale* (=NN=) e' un modello computazionale composto da neuroni artificiali, le sue proprieta' sono:
- non linearita', la funzione che elabora la risposta non e' lineare
- input-output mapping, ha un ingresso e un'uscita
- fault tolerance, il task sulla quale e' addestrata e' distribuito
- incremental training, possibile continuare l'addestramento nel momento in cui ci siano nuovi dati

Un =NN= puo' essere
- *supervisionato*
  - insieme di addestramento con input e output _desiderato_
  - usi in *classificazione*, *riconoscimento*, *diagnostica*, *regressione*
- *non supervisionato*
  - insieme di addestramento _non etichettati_
  - usi in *clustering*

** Architetture
- *single layer feed forward*
  - grossi limiti, sorpassato
- *multi layer feed forward*
  - livelli nascosti, non interagiscono direttamente con il mondo esterno
- *recurrent*
  - livelli nascosti
  - feedback loop

* Perceptron
Primo esempio di rete neurale (1958), può risolvere semplici problemi di classificazione nel caso in cui il problema sia *linearmente separabile*.

#+begin_quote
Un problema si dice /linearmente separabile/ se i dati rappresentati nello spazio sono divisibili nelle loro classi tramite una linea retta, detta *decision boundary*.
#+end_quote

La rete del /perceptron/ e' semplice, con $p-1$ neuroni di input e un neurone di /bias/. Il neurone di output effettua la somma pesata, detta *campo locale*:
\[v_{}_{j} = \sum^{p}_{i=0} w_{ji}x_{i}\]

La *funzione di attivazione*:
\begin{math}
\phi(v_{j}) =
\begin{cases}
1 \qquad \text{se } v_{j} > 0 \\
-1 \qquad \text{altrimenti}
\end{cases}
\end{math}

L'apprendimento e' effettuato tramite un'algoritmo iterativo dove $\eta$ e' il *learning rate*:

\begin{algorithm}
\caption{Algoritmo di Apprendimento del Percettrone}
\begin{algorithmic}[1]
\Procedure{Learning-Perceptron}
\State{n \gets 0}
\State{\text{inizializza } w(n) \text{ casualmente}}
\While{\text{ci sono esempi classificati erroneamente}}
\State{(x(n),d(n))\gets \text{esempio mis-classificato}}
\If{d(n) = 1}
\State{w(n+1)\gets w(n) + \eta x(n)}
\EndIf
\If{d(n)=-1}
\State{w(n+1)\gets w(n) - \eta x(n)}
\EndIf
\State{n \gets n +1}
\EndWhile
\end{algorithmic}
\end{algorithm}

Con il cambiamento dei pesi $w$ si sta spostando la *decision boundary*, tracciata perpendicolarmente al vettore dei pesi.

L'algoritmo si ferma quando tutti gli elementi del /training set/ sono classificati correttamente. A quel punto la configurazione di pesi e' corretta.

** Teorema di Convergenza
#+begin_quote
Se esiste una soluzione - quindi le due classi sono linearmente separabili - l'algoritmo di apprendimento termina, trovandola.
#+end_quote

Geometricamente, se $w \cdot x > 0 \land -90 < \alpha < \180$
\[w(n) \cdot x(n) = ||w|| \cdot ||x|| \cos (\alpha)\]

Quindi la modifica del vettore pesi porta a cambiare la *decision boundary* (retta perpenticolare al vettore pesi) che accomodi l'input mal classificato corrente. Lo spostamento della *boundary* puo' causare altri input ad essere mal classificati.

Inizialmente i pesi sono posti a 0.
La dimostrazione procede portando tutti i dati in un'unica classe $C$ che unisca $C_{1}$ e $C_{}_{}_{}_{}_{}_{2}$ (in questo caso si restituisce 1 a $\lnot x$) e mostrando che esistono un lower bound $\alpha$ e un upper bound $\beta$ al numero di passi di iterazione $k$.

Per la sequenza di stimoli vengono modificati i pesi:
\begin{align*}
w(1) = w(0) + x(0) \\
w(2) = w(1) + x(1) \\
\cdots \\
w(k+1) = w(k) + x(k)
\end{align*}

In quanto $k$ ha un lower bound quadratico all'infinito e un upper bound $k$ non puo' crescere all'infinito, pena l'inconsistenza di questi limiti.

- $$\alpha = \min{(w^{*T} x(i))} \qquad  (\forall i \in 0\dots k)$$
- $$\beta = (\max{||x(i)||})^2 \qquad (\forall x(i) \in C)$$

\[k \le \frac{ \beta|| w^{*}  ||^2 }{\alpha^{}^2}\]

** XOR
Un classico problema non linearmente risolvibile e' quello dello XOR. Questo problema rimase aperto per un periodo, portando ad una crisi nella ricerca che apri' la strada a nuove strutture per i =NN=.

* Multilayer Perceptron
Nel 1969 l'entusiasmo iniziale viene meno quando si mostrano molti problemi non linearmente separabili a cui i percettroni non potevano dare soluzione.
Le reti multilivello permettono di discriminare aree convesse nello spazio, superando i limiti dei percettroni singoli.

** Adaline
=Adaptive Linear Neural=
Questa struttura modifica come vengono aggiornati i pesi, si focalizza sulla riduzione dell'errore.
- mentre il percettrone aveva l'obiettivo di diminuire gli input misclassificati
- qui l'obiettivo e' la riduzione dell'errore globale

L'architettura del neurone e' differente, non più una funzione di attivazione ma una funzione lineare.

Si studia la derivata di errore in relazione al peso, se la derivata e' negativa allora la funzione errore sta diminuendo, si continua ad aumentare il peso.
Se la derivata e' positiva l'errore e' in salita e si diminuisce il peso.

Formalmente si descrivono le coppie features-valore nell'esempio $k$:
\[(x^{k} , d^{k})\]
L'errore viene definito come
\begin{align*}
E^{k} (w) &= \frac{1}{2}(d^{k} - y^{k})^{2} \\
&= \frac{1}{2}(d^{k} - \sum^{m}_{j=0} x^{k}_{j} w_{j})^{2}
\end{align*}

Quindi definiamo l'errore per l'esempio $k$ come la differenza tra il valore desiderato $d^{k}$ e quello ottenuto $y^{k}$.
Quindi l'errore totale sulla rete e'
\[E_{\text{tot}} = \sum^{N}_{k=1} E^{k}\]

Si cerca di minimizzare questo valore ragionando *pattern-by-pattern*, calcolando e minimizzando l'errore sulla singola istanza $k$.

* Self-Organizing Maps
=SOM=
/Apprendimento non supervisionato/
Strutture bidimensionali dove i neuroni sono disposti in una griglia.
- la griglia e' solo una visualizzazione, non ci sono pesi tra i neuroni
- ogni neurone ha un suo vettore pesi $w_{i}$ della stessa dimensione dell'input
  - anche detti *prototype vector*, rappresentazioni associate al neurone
  - qual'e' il _tipo di stimolo_ che il neurone rappresenta
- l'input e' un vettore $x$ di dimensione $n$

La *best matching unit* (=BMU=) e' il neurone attivato maggiormente dall'input
- corrisponde meglio allo stimolo
- attivazione e' il prodotto scalare $x \cdot w_{i}$
- questo e' anche il neurone con la minima distanza euclidea da $x$
  - $$i: \forall i ||x - w_{i}|| \le ||x - w_{j}||$$
  - se tutti i vettori hanno la stessa norma la minima distanza euclidea e il massimo prodotto scalare vanno di pari passo, se non e' cosi' viene considerata la distanza come definizione

Il /learning/ va a modificare i pesi del =BMU= in modo da aumentare la probabilita' che questo sia il neurone vincente per lo stesso input o simili.
- avviciniamo il vettore pesi di =BMU= allo stimolo
** Learning
Una forma di *competitive learning*
- una volta trovata la =BMU= si correggono i pesi
- $$w_{i}(n+1) = w_{i}(n) + \eta(n)(x - w_{i}(n))$$
  - dopo la correzione $w_{i}$ e' piu' simile a $x$

Il *learning rate* solitamente decresce con il procedere dell'apprendimento, il cambiamento in generale e' regolato:
\[\eta(n) = \]

Inoltre a ogni neurone $i$ e' assegnato un vicinato (/neighberhood/) cui e' propagata la correzione dei pesi.
- una gaussiana che decresce con l'aumentare della distanza tra neuroni
- cooperazione tra i neuroni
\[w_{j} (n+1)=  w_{j} (n+1) + \eta (n) h_{j,i} (n) (x - w_{j} (n))\]
\[h_{j,i} (n) = \exp \Big (- \frac{d_{j,i}^2}{2\sigma (n)^2}\Big )\]
\[\sigma (n) = \sigma _{0}\]

Ci sono 2 fasi, a grosso modo
- auto organization
- convergence


*topographic Error*
\[\text{TE} = \frac{1}{L} \sum_{l=1}^{L} u(x_{l})\]

* Hopfield Networks
- see: https://transno.com/doc/3y-nWb7O0Jl#o-TxSokX9WzM
I [[id:ce52162b-a751-4740-bf43-f2b4a74d585b][Hopfield Networks]] sono una forma di rete neurale ricorrente, popolarizzata da [[id:6a80e38f-f447-4a10-8162-7a6ca9b98df0][John Hopfield]] nel 1982.
- ogni neurone e' collegato a ogni altro tranne se stesso con pesi simmetrici
- la attivazione dei neuroni e' calcolata in maniera *asincrona*
  - scelta una unità la sua attività alpha viene calcolata dalle equazioni

\[v_j = \sum_{i=0}^{N} w_{ji}y_{i}(n)\]
\begin{align*}
\phi(v_{j})(n)=
\begin{cases}
1 \qquad &\text{if } v_j (n) >0\\
-1 \qquad &\text{if } v_j (n) <0\\
\phi(v_j)(n-1) \qquad &\text{if } v_j (n) =0
\end{cases}
\end{align*}

In queste configurazioni si possono raggiungere degli *stati stabili*, dove:
\[\forall i, y_{i} (n+1) = y_{i}(n)\]
In generale la negazione di uno stato stabile rimane stabile.

Si dimostra un *teorema di convergenza* per cui da un qualsiasi stato di partenza e' garantito si raggiunge in un numero di passi finiti a uno stato stabile.

Le memorie fondamentali sono inserite all'interno della rete e questa imparerà a riconoscere versioni parziali/corrotte di queste sue memorie.
- la rete fa *pattern completion*

Il problema è:
- come individuare la configurazione di pesi cui corrispondono stati stabili le configurazioni di attivazioni delle memorie fondamentali

** Storage
Le memorie fondamentali sono *attrattori* di versioni corrotte in input.
- il principio di *Hebb* per l'apprendimento ci aiuta nello storage

#+caption: D.O. Hebb, 1949
#+begin_quote
When an axon of cell A is near enough to excite a cell B and repeatedly or persistently takes part in firing it, some growth process or metabolic change takes place in one or both cells such that A's efficiency, as one of the cells firing B, is increased. [[id:42e4fdc6-7b24-4b1d-96b0-0c660fbf7b3a][$cit]]
#+end_quote
- fire together means strong connection
  - i neuroni si rafforzano

Nella rete di Hopfield neuroni concordi avranno pesi tra loro positivi: si rafforzano.
Generalizzando il principio vogliamo che neuroni che vogliamo opposti siano connessi da sinapsi negative.

In questa fase si decidono le *memorie fondamentali*
- le configurazioni di attivazione dei neuroni
Date queste vengono calcolati *one-shot* i pesi.

Data una singola memoria fondamentale e' semplice:
\[w_{ij} = f_{}_1(i) \times f_1(j)\]
- attivazioni discorde indeboliscono la connessione

Date $M$ memorie fondamentali, $f_1 \cdots f_{M}$ di dimensioni $N$.
\begin{align*}
w_{ji} =
\begin{cases}
\frac{1}{M}\sum_{k=1}^{M} f_{k}(i) \times f_{k}(j) \qquad &j \neq i \\
0 &j = i
\end{cases}
\end{align*}
- questa regola funziona bene se abbiamo poche memorie fondamentali e non in conflitto
** Retrieval
1. Initialization
   - si imposta la rete nello stato presentato $x$
2. Iteration until convergence
   - update degli elementi asincronicamente scegliendo unita' random
\[v_j = \sum_{i=0}^{N} w_{ji}y_{i}(n)\]
\begin{align*}
\phi(v_{j})(n)=
\begin{cases}
1 \qquad &\text{if } v_j (n) >0\\
-1 \qquad &\text{if } v_j (n) <0\\
\phi(v_j)(n-1) \qquad &\text{if } v_j (n) =0
\end{cases}
\end{align*}
3. Convergence to stable state
4. Output

** Convergence Theorem
Dato un qualsiasi stato iniziale la rete converge a uno stato stabile.
- non e' piu' possibile modificare lo stato della rete attraverso la regola di aggiornamento

Il teorema si basa sul concetto di *energia*.
- *energy is bad!*

Una rete con alta energia e' molto propensa di modificare di stato, molto instabile.
Al contrario *una bassa energia indica una rete stabile*.

- date $N$ unita' ci sono $2^{N}$ possibili stati della rete
- a ogni stato si associa un livello di energia
- si prova che ogni cambiamento di stato porta a un abbassamento dell'energia
- c'e' un momento in cui lo stato (stabile) non può più modificarsi in un altro stato

La definizione di energia:
\[E = - \frac{1}{2} \sum_{i}\sum_{j}w_{ij} y_{i}y_{j}\]
- ogni prodotto interno e' positivo con
  - $y$ concorde e $w$ positivo
  - $y$ discorde e $w$ negativo
- la sommatorie e' negata, quindi coppie di neuroni per cui il prodotto e' positivo portano il livello di energia ad abbassarsi

\begin{align*}
E = - \frac{1}{2} \sum_{i}\sum_{j}w_{ij} y_{i}y_{j} = - \frac{1}{2} \sum_{i}\sum_{j}w_{ij} y_{i}y_{j}
\end{align*}
** Qualities
- complete partial patterns
- generalize, given similar inputs to memory they recover the corresponding information
- fault tolerant, if synapses get broken the networks still works
- extraction fo prototypes, a network learning similar information it creates a prototype
- Hebb like
** Drawbacks
- spurious states
- not all fundamental memories are stable states
- storage capacity with few errors given $N$ units is $0.14 N$

* Boltzmann Machines
Le [[id:a6beb0ba-31e4-4a91-8cce-eb48aee3e588][Boltzmann Machines]] utilizzano la rete per costruire interpretazioni degli input sensoriali.
- input rappresentato dalle unità visibili
- interpretazione rappresentata dallo stato delle unità nascoste
- l'errore della interpretazione viene rappresentato dall'energia
- le =BM= sono modelli generativi, apprendono a riprodurre a livello visibile il =TS=
  - l'apprendimento vuole massimizzare il prodotto delle probabilità assegnate dalla =BM= ai vettori binari nel =TS=
  - si procede calcolando le probabilità assegnate con il =TS= e facendo *sampling* in base a queste probabilità
  - si arriva a una /fantasy/ che la =BM= tende a generare

** Restricted Boltzmann Machines
=RBM=
Reference: [[id:a46ae609-8c71-4a40-a87f-33d4640917af][A Practical Guide to Training Restricted Boltzmann Machines]]

- ogni neurone hidden è connesso a ogni neurone visible
- i neuroni hidden non sono connessi ad altri neuroni hidden
- i neuroni visible non sono connessi ad altri neuroni visible

In fase di training si presentano input in livello visible e si modificano le attivazioni della rete hidden, non più in maniera deterministica ma stocastica.
- in base a temperatura e /energy gap/
  - anche se assecondando Hilton la temperatura viene ignorata impostandola sempre a 1
- sfuggendo a minimi locali di energia

Nel calcolo del /energy gap/ tutti i termini non contenenti $i$ sono eliminati in quanto identici nei casi $s_{i} = 0, s_{i} = 1$.
\[\Delta E_{i} =  \Sum w_{ij}  s_{i} + b_{i} \quad \forall j\]
** Contrastive Divergence
Algoritmo di apprendimento basato su solamente due passaggi tra livello visible e hidden.
- /A very surprising short-cut/

Correzione della discrepanza tra *dato* e *ricostruzione* della rete in due passi.
- quindi tra l'elemento del =TS= presentato e la ricostruzione successiva a livello visible fatta dalla rete addestrata

I passaggi sono:
- data $\to$ hidden $\to$ reconstruction $\to$ hidden

\[\Delta w_{ij} = \epsilon (\lang v_{i} h_{j} \rang^{0} - \lang v_{i} h_{j} \rang^{1}) \]
Quindi i prodotti di attivazione  presi a $t=0$ e $t=1$.
- $v$ sta per visible, $h$ sta per hidden
- momento di /clamping/ del training pattern a livello /visible/
- momento di /recostruction/ a livello visible
  - può essere diversa da quella presentata inizialmente: una /fantasy/ della rete che l'algoritmo mira a correggere

L'idea è che ci si accorge che alla rete piace divagare rispetto al =TS= dopo solo due passi, è inutile lasciare che la rete del genere si stabilizzi in quanto non genererà i  pattern desiderati.

Ogni neurone riconosce una feature specifica.

** Deep Neural Networks
Steps to learning:
1. raw input vector representation
2. slightly higher level representation
3. ...
4. very high level representation

* Supervised Learning
Dati di apprendimento sono etichettati.
** Single Layer feed-forward
=Perceptron=
Non ci sono neuroni nascosti.
** Multi Layer feed-forward
=Input Layer= \to =Hidden Layer= \to =Output Layer=
- le unità nascoste estraggono dinamiche di _livello superiore_
Può essere completamente (ogni neurone è connesso a ognuno dei precedenti) o parzialmente connesso.
Tratta dati non linearmente separabili.

L'algoritmo di =back-propagation= minimizza l'errore con la tecnica della discesa del gradiente
- per questo la funzione associata al percettrone deve essere derivabile

Una tipica funzione di attivazione é la =sigmoide=
\[\phi(v_{j}) = \frac{1}{1+e^{-av_{j}}}\]
con $a > 0$

\[v_{j} = \sum w_{ji}y_{i}\]
dove $y_{i}$ é l'output del neurone $i$

$\phi$ si avvicina alla funzione gradino (/step/) al crescere di $a$.

*** Backpropagation Algorithm
Cerca pesi che minimizzano l'errore totale della rete sul =Training Set=.
Consiste nella applicazione ripetuta di 2 passi:
1. *forward pass*, la rete viene attivata con un esempio e si calcola l'errore di ogni neurone di output
2. *backward pass*, l'errore di rete é utilizzato per aggiornare i pesi

Il processo é più complesso che per =Adaline= in quanto i nodi nascosti contribuiscono all'errore.
Partendo dall'output layer l'errore viene propagato all'indietro attraverso la rete (layer by layer), calcolando ricorsivamente il *gradiente locale* di ogni peso.

Calcoliamo l'errore partendo dal layer di output, al $n$ -esimo training example:
\begin{align*}
e_{j} (n) &= d_{j}(n) - y_{j}(n) \\
E(n) &= \frac{1}{2} \sum e_{j}^{2} (n) \\
E_{}_{AV} &= \frac{1}{N}\sum^{N}_{n=1} E(n)
\end{align*}

Aggiornamento dei pesi:
\begin{align*}
w_{ji} &= w_{ji} + \Delta w_{ji} \\
\Delta w_{ji} &= - \eta \frac{\delta E}{\delta w_{ji}} \quad \eta > 0\
\end{align*}
- il delta viene corretto nella direzione *opposta* del gradiente di $E$
  - il gradiente é l'insieme di tutte le derivate di $E$ in funzione dei pesi
    - tante quante i pesi, ogni variazione di peso ha un impatto sull'errore totale della rete

** Radial-Basis Function Neural Network
=RBF= - [[id:b2bc8c65-d796-4070-8cc3-51dd514d7679][Radial Basis Function Network]]
Una funzione radiale restituisce un output dipendente dalla distanza di input e un vettore interno. Una tipologia di =RBF= molto diffuse sono le *Gaussiane*.
- se il problema lo consente le =RBF= possono delimitare più facilmente aree con meno neuroni
- le architetture basate su =RBF= sono solitamente con un unico livello nascosto, con $m_1$ funzioni radiali
  - $m$ input
- le funzioni di attivazione =RBF= sono utilizzate nel livello /hidden/
  - il livello di uscita è lineare
\[\phi_{}_{1} \cdots \phi_{k}\]
\[y = w_{1}\phi_{1} (||x - t_{1}||) + \dots + w_{m_{1}}\phi_{m_{1}}(||x - t_{m_{1}}||)\]
- il centro della funzione radiale é $t$
  - un generico centro $t_k$ ha $m$ componenti[fn:differenza]
  - le componenti dei centri fanno le veci dei pesi del neurone /hidden/ del /multilayer perceptron/
- un altro iperparametro é lo /spread/ $\sigma$
  - indica quanto la funzione sia aperta o chiusa
  - /spread/ grande significa proiezioni (circonferenze) grandi
- tutti i neuroni nascosti diventano sensibili a input vicini al loro centro
  - la sensibilità dei neuroni può essere aggiustato tramite lo /spread/ $\sigma$, grande significa meno sensibile

I pesi dell'uscita $y$ individua il /decision boundary/ nel nuovo spazio $\phi$
- questo in quanto il problema - precedentemente non linearmente separabile - viene trasposto in un nuovo spazio dalle $\phi$ in cui é linearmente separabile

Si cerca una funzione $F: R^m \Rightarrow R$ che le condizioni di interpolazione $F(x_i) = d_i$
Si cercano i pesi che definiscano $F(x)$
- per questo si passa attraverso *pseudo-inversione* matriciale


*** Interpolation
$\{x_i \in R^{m} , i = 1 \cdots N\}$ set di punti
$\{d_i \in R , i = 1 \cdots N\}$ set numeri reali
Cerchiamo una funzione $F: R^m \Rightarrow R$
Condizione di interpolazione:
\[F(x_i) = d_{i}\]
Si deriva dalla definizione di $F(x)$ il risultato del calcolo sulla matrice $N$
\[\Phi w = d\]
- $\Phi$ matrice *quadrata* delle $\phi$
  - come se prendessimo come centri radiali tutte gli esempi $x_{}_i$
  - nell'uso concreto i centri saranno meno
- $w$ vettore delle $w_i$
- $d$ vettore delle $d_i$

$\Phi$ é una matrice quadrato in quanto tutti gli $i$ input vengono utilizzati per ogni riga come centro della =RBF=
Definita la *pseudo-inversa* $$\Phi^{+}= (\Phi^{T}\Phi)^{-1}\Phi^{T}$$
I pesi si trovano risolvendo il sistema lineare
\[w^T = \Phi^+ d^T\]

L'algoritmo schematicamente allora consiste in tre passi:
1. scegli i centri casualmente
2. calcola la /spread/ della funzione =RBF= con la tecnica di normalizzazione
3. trova i pesi utilizzando il metodo di pseudo-inversione
** Extreme Learning Machine
=ELM=

[[id:ccdb3de2-8856-46f8-875d-1bbd5a8ab52b][Extreme learning machine: Theory and applications]]
#+begin_quote
$\text{Theorem 2.1} \quad$ Given a standard =SLFN= with $N$ hidden nodes and activation function $g: R\to R$ which is infinitely differentiable in any interval, for $N$ arbitrary distinct samples $(x_{i},t_{i})$, where $x_{i}\in R^{n}$ and $t_{i} \in R^{m}$, for any $w_{i}$ and $b_{i}$ randomly chosen from any intervals of $R^{n}$ and $R$, respectively, according to any continuous probability distribution, then with probability one, the hidden layer output matrix $H$ of the =SLFN= is invertible and $|| H\beta - T || = 0$.
#+end_quote

#+begin_quote
$\text{Theorem 2.2} \quad$ Given any small positive value $\epsilon > 0$ and activation function $g: R\to R$ which is infinitely differentiable in any interval, there exists $\tilde{N} \le N$ such that for $N$ arbitrary distinct samples $(x_{i},t_{i})$, where $x_{i}\in R^{n}$ and $t_{i} \in R^{m}$, for any $w_{i}$ and $b_{i}$ randomly chosen from any intervals of $R^{n}$ and $R$, respectively, according to any continuous probability distribution, then with probability one, $|| H_{N \times \tilde{N}} \beta_{\tilde{N}\times m} - T_{N\times m} || < 0$.
#+end_quote

Piu' piccola e' la norma dei pesi migliori sono le performance della generalizzazione, tendenzialmente.
- per questo l'algoritmo proposto tende a buone prestazioni per =FFNN=
* Unsupervised Learning
In questa categoria si collocano le *Reti Neurali Profonde*:
- organizzano i propri livelli gerarchicamente
  - selezione delle feature più importanti a scapito di quelle ignorabili
  - *unsupervised feature learning*
- le caratteristiche dei dati che permettano la risoluzione del problema sono trovate in maniera automatica
  - non serve pre-precessing da parte di esperti sui dati
  - *representation learning*

La complessità di una rete è determinata da:
- profondità
- numero delle connessioni tra i neuroni
- numero di pesi diversi tra i neuroni
** Reti Neurali Convoluzionali
=CNN= - [[id:de384f8e-17f3-4940-b4c3-23147f629bec][Convolutional Neural Network]]

Molto utilizzate per lavorare su immagini.
- *processamento locale*
  - i neuroni di un certo livollo sono connessi ad altri neuroni del livello precedente solo localmente
  - riduzione del numero delle connessioni
  - specializzazioni dei neuroni su una zona dell'input
    - parti diverse della rete si occupano di compiti diversi

Il livello convolutivo lavora come un filtro, processando i valori del livello precedente.
Il processo procede per /stride/ man mano applicando il filtro.
- lo /stride/ individua di quanto si sposta la finestra passo dopo passo
- per evitare che la finestra fuoriesca dalla matrice si aggiunge del padding della grandezza giusta

Solitamente si utilizzano rete neurali multi dimensionali:
- ogni livello di neuroni viene chiamato *feature map*
  - una particolare mappa apprende una particolare feature dell'input
- sia input che output hanno multiple feature map
- diverse feature map insieme compongono un *tensore*

Un livello di neuroni si occupa di un task di compressione dell'informazione chiamato *pooling* (/downsampling/)
- questo task genera delle feature map di dimensioni minori
- l'aggregazione dell'informazione puó avvenire utilizzando *max-pooling* o *average-pooling*
* RELU
=REctified Linear Unit=
\[f(u) = \max (0, u)\]
- funzione non derivabile
  - derivata 0 per valori negativi
  - derivata 1 per valori positivi
Questa funzione porta a una /attivazione sparsa/, dove non tutti i neuroni vengono attivati portando alcune componenti del gradiente a 0.
- questo permette *pruning automatico*
  - nelle reti si tende ad abbondare con il numero di neuroni o di livelli necessari al problema
  - in questo modo la rete può annullare delle componenti a piacimento durante il training



[fn:differenza] deve essere compatibile con l'input $x_k$ per poter effettuare la distanza.
