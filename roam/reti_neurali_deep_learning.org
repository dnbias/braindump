:PROPERTIES:
:ID:       db3694d3-01ed-4a3c-ba6b-74190b348e6d
:ROAM_ALIASES: RNDL
:END:
#+title: Reti Neurali & Deep Learning
#+filetags: university
#+date: [2022-09-22 Thu 19:16]
- Prof.essa Valentina Gliozzi, Prof.essa Rossella Cancelliere

* Principi
- le reti neurali sono strutture che simulano il comportamento del cervello umano
  - in particolare l'unita' base: il *neurone*
    - funzioni: /raccoglie, elabora, propaga/ segnali

La struttura in particolare e' composta da diverse parti:
1. neuroni di *input*
2. neurone di *output*
   - a questo e' associato un ulteriore input: il *bias*
     - la tendenza ad attivarsi
3. la somma *pesata* viene passata a una *funzione di attivazione*, da questa deriva il risultato

Una *rete neurale* (=NN=) e' un modello computazionale composto da neuroni artificiali, le sue proprieta' sono:
- non linearita', la funzione che elabora la risposta non e' lineare
- input-output mapping, ha un ingresso e un'uscita
- fault tolerance, il task sulla quale e' addestrata e' distribuito
- incremental training, possibile continuare l'addestramento nel momento in cui ci siano nuovi dati

Un =NN= puo' essere
- *supervisionato*
  - insieme di addestramento con input e output _desiderato_
  - usi in *classificazione*, *riconoscimento*, *diagnostica*, *regressione*
- *non supervisionato*
  - insieme di addestramento _non etichettati_
  - usi in *clustering*

** Architetture
- *single layer feed forward*
  - grossi limiti, sorpassato
- *multi layer feed forward*
  - livelli nascosti, non interagiscono direttamente con il mondo esterno
- *recurrent*
  - livelli nascosti
  - feedback loop

* Perceptron
Primo esempio di rete neurale (1958), puo' risolvere semplici problemi di classificazione nel caso in cui il problema sia *linearmente separabile*.

#+begin_quote
Un problema si dice /linearmente separabile/ se i dati rappresentati nello spazio sono divisibili nelle loro classi tramite una linea retta, detta *decision boundary*.
#+end_quote

La rete del /perceptron/ e' semplice, con $p-1$ neuroni di input e un neurone di /bias/. Il neurone di output effettua la somma pesata, detta *campo locale*:
\[v_{}_{j} = \sum^{p}_{i=0} w_{ji}x_{i}\]

La *funzione di attivazione*:
\begin{math}
\phi(v_{j}) =
\begin{cases}
1 \qquad \text{se } v_{j} > 0 \\
-1 \qquad \text{altrimenti}
\end{cases}
\end{math}

L'apprendimento e' effettuato tramite un'algoritmo iterativo dove $\eta$ e' il *learning rate*:

\begin{algorithm}
\caption{Algoritmo di Apprendimento del Percettrone}
\begin{algorithmic}[1]
\Procedure{Learning-Perceptron}
\State{n \gets 0}
\State{\text{inizializza } w(n) \text{ casualmente}}
\While{\text{ci sono esempi classificati erroneamente}}
\State{(x(n),d(n))\gets \text{esempio mis-classificato}}
\If{d(n) = 1}
\State{w(n+1)\gets w(n) + \eta x(n)}
\EndIf
\If{d(n)=-1}
\State{w(n+1)\gets w(n) - \eta x(n)}
\EndIf
\State{n \gets n +1}
\EndWhile
\end{algorithmic}
\end{algorithm}

Con il cambiamento dei pesi $w$ si sta spostando la *decision boundary*, tracciata perpendicolarmente al vettore dei pesi.

L'algoritmo si ferma quando tutti gli elementi del /training set/ sono classificati correttamente. A quel punto la configurazione di pesi e' corretta.

** Teorema di Convergenza
#+begin_quote
Se esiste una soluzione - quindi le due classi sono linearmente separabili - l'algoritmo di apprendimento termina, trovandola.
#+end_quote

Geometricamente, se $w \cdot x > 0 \land -90 < \alpha < \180$
\[w(n) \cdot x(n) = ||w|| \cdot ||x|| \cos (\alpha)\]

Quindi la modifica del vettore pesi porta a cambiare la *decision boundary* (retta perpenticolare al vettore pesi) che accomodi l'input mal classificato corrente. Lo spostamento della *boundary* puo' causare altri input ad essere mal classificati.

Inizialmente i pesi sono posti a 0.
La dimostrazione procede portando tutti i dati in un'unica classe $C$ che unisca $C_{1}$ e $C_{}_{}_{}_{}_{}_{2}$ (in questo caso si restituisce 1 a $\lnot x$) e mostrando che esistono un lower bound $\alpha$ e un upper bound $\beta$ al numero di passi di iterazione $k$.

Per la sequenza di stimoli vengono modificati i pesi:
\begin{align*}
w(1) = w(0) + x(0) \\
w(2) = w(1) + x(1) \\
\cdots \\
w(k+1) = w(k) + x(k)
\end{align*}

In quanto $k$ ha un lower bound quadratico all'infinito e un upper bound $k$ non puo' crescere all'infinito, pena l'inconsistenza di questi limiti.

- $$\alpha = \min{(w^{*T} x(i))} \qquad  (\forall i \in 0\dots k)$$
- $$\beta = (\max{||x(i)||})^2 \qquad (\forall x(i) \in C)$$

\[k \le \frac{ \beta|| w^{*}  ||^2 }{\alpha^{}^2}\]

** XOR
Un classico problema non linearmente risolvibile e' quello dello XOR. Questo problema rimase aperto per un periodo, portando ad una crisi nella ricerca che apri' la strada a nuove strutture per i =NN=.

* Multilayer Perceptron
Nel 1969 l'entusiasmo iniziale viene meno quando si mostrano molti problemi non linearmente separabili a cui i percettroni non potevano dare soluzione.
Le reti multilivello permettono di discriminare aree convesse nello spazio, superando i limiti dei percettroni singoli.

** Adaline
=Adaptive Linear Neural=
Questa struttura modifica come vengono aggiornati i pesi, si focalizza sulla riduzione dell'errore.
- mentre il percettrone aveva l'obiettivo di diminuire gli input misclassificati
- qui l'obiettivo e' la riduzione dell'errore globale

L'architettura del neurone e' differente, non piu' una funzione di attivazione ma una funzione lineare.

Si studia la derivata di errore in relazione al peso, se la derivata e' negativa allora la funzione errore sta diminuendo, si continua ad aumentare il peso.
Se la derivata e' positiva l'errore e' in salita e si diminuisce il peso.

Formalmente si descrivono le coppie features-valore nell'esempio $k$:
\[(x^{k} , d^{k})\]
L'errore viene definito come
\begin{align*}
E^{k} (w) &= \frac{1}{2}(d^{k} - y^{k})^{2} \\
&= \frac{1}{2}(d^{k} - \sum^{m}_{j=0} x^{k}_{j} w_{j})^{2}
\end{align*}

Quindi definiamo l'errore per l'esempio $k$ come la differenza tra il valore desiderato $d^{k}$ e quello ottenuto $y^{k}$.
Quindi l'errore totale sulla rete e'
\[E_{\text{tot}} = \sum^{N}_{k=1} E^{k}\]

Si cerca di minimizzare questo valore ragionando *pattern-by-pattern*, calcolando e minimizzando l'errore sulla singola istanza $k$.

* Self-Organizing Maps
=SOM=
/Apprendimento non supervisionato/
Strutture bidimensionali dove i neuroni sono disposti in una griglia.
- la griglia e' solo una visualizzazione, non ci sono pesi tra i neuroni
- ogni neurone ha un suo vettore pesi $w_{i}$ della stessa dimensione dell'input
  - anche detti *prototype vector*, rappresentazioni associate al neurone
  - qual'e' il _tipo di stimolo_ che il neurone rappresenta
- l'input e' un vettore $x$ di dimensione $n$

La *best matching unit* (=BMU=) e' il neurone attivato maggiormente dall'input
- corrisponde meglio allo stimolo
- attivazione e' il prodotto scalare $x \cdot w_{i}$
- questo e' anche il neurone con la minima distanza euclidea da $x$
  - $$i: \forall i ||x - w_{i}|| \le ||x - w_{j}||$$
  - se tutti i vettori hanno la stessa norma la minima distanza euclidea e il massimo prodotto scalare vanno di pari passo, se non e' cosi' viene considerata la distanza come definizione

Il /learning/ va a modificare i pesi del =BMU= in modo da aumentare la probabilita' che questo sia il neurone vincente per lo stesso input o simili.
- avviciniamo il vettore pesi di =BMU= allo stimolo
** Learning
Una forma di *competitive learning*
- una volta trovata la =BMU= si correggono i pesi
- $$w_{i}(n+1) = w_{i}(n) + \eta(n)(x - w_{i}(n))$$
  - dopo la correzione $w_{i}$ e' piu' simile a $x$

Il *learning rate* solitamente decresce con il procedere dell'apprendimento, il cambiamento in generale e' regolato:
\[\eta(n) = \]

Inoltre a ogni neurone $i$ e' assegnato un vicinato (/neighberhood/) cui e' propagata la correzione dei pesi.
- una gaussiana che decresce con l'aumentare della distanza tra neuroni
- cooperazione tra i neuroni
\[w_{j} (n+1)=  w_{j} (n+1) + \eta (n) h_{j,i} (n) (x - w_{j} (n))\]
\[h_{j,i} (n) = \exp \Big (- \frac{d_{j,i}^2}{2\sigma (n)^2}\Big )\]
\[\sigma (n) = \sigma _{0}\]

Ci sono 2 fasi, a grosso modo
- auto organization
- convergence


*topographic Error*
\[\text{TE} = \frac{1}{L} \sum_{l=1}^{L} u(x_{l})\]



* Supervised Learning
Dati di apprendimento sono etichettati.
** Single Layer feed-forward
=Perceptron=
Non ci sono neuroni nascosti.
** Multi Layer feed-forward
=Input Layer= \to =Hidden Layer= \to =Output Layer=
- le unitá nascoste estraggono dinamiche di _livello superiore_
Può essere completamente (ogni neurone é connesso a ognuno dei precedenti) o parzialmente connesso.
Tratta dati non linearmente separabili.

L'algoritmo di =back-propagation= minimizza l'errore con la tecnica della discesa del gradiente
- per questo la funzione associata al percettrone deve essere derivabile

Una tipica funzione di attivazione é la =sigmoide=
\[\phi(v_{j}) = \frac{1}{1+e^{-av_{j}}}\]
con $a > 0$

\[v_{j} = \sum w_{ji}y_{i}\]
dove $y_{i}$ é l'output del neurone $i$

$\phi$ si avvicina alla funzione gradino (/step/) al crescere di $a$.


*** Backprapagation Algorithm
Cerca pesi che minimizzano l'errore totale della rete sul =Training Set=.
Consiste nella applicazione ripetuta di 2 passi:
1. *forward pass*, la rete viene attivata con un esempio e si calcola l'errore di ogni neurone di output
2. *backward pass*, l'errore di rete é utilizzato per aggiornare i pesi

Il processo é più complesso che per =Adaline= in quanto i nodi nascosti contribuiscono all'errore.
Partendo dall'output layer l'errore viene propagato all'indietro attraverso la rete (layer by layer), calcolando ricorsivamente il *gradiente locale* di ogni peso.

Calcoliamo l'errore partendo dal layer di output, al $n$ -esimo training example:
\begin{align*}
e_{j} (n) &= d_{j}(n) - y_{j}(n) \\
E(n) &= \frac{1}{2} \sum e_{j}^{2} (n) \\
E_{}_{AV} &= \frac{1}{N}\sum^{N}_{n=1} E(n)
\end{align*}

Aggiornamento dei pesi:
\begin{align*}
w_{ji} &= w_{ji} + \Delta w_{ji} \\
\Delta w_{ji} &= - \eta \frac{\delta E}{\delta w_{ji}} \quad \eta > 0\
\end{align*}
- il delta viene corretto nella direzione *opposta* del gradiente di $E$
  - il gradiente é l'insieme di tutte le derivate di $E$ in funzione dei pesi
    - tante quante i pesi, ogni variazione di peso ha un impatto sull'errore totale della rete

* Unsupervised Learning
