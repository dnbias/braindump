:PROPERTIES:
:ID:       4ed14fbf-ae6e-4536-b4d7-5897fcbdd016
:END:
#+title: Sistemi Intelligenti
#+date: [2022-02-28 Mon 14:23]
#+filetags: university
Professoressa: Cristina Baroglio
* Terminologia
- *AI* coniato da [[id:1bd058f7-555b-425a-a779-8073c6889c84][John McCarthy]]
- *Dato*, simbolo grezzo
- *Informazione*, un dato elaborato
- *Conoscenza*, compo di informazioni correlate tra loro
- *Automazione*,
- *Autonomia*,
* Test di Turing
- test per definire se un computer e' intelligente, o se un programma lo e'
  + in linguaggio naturale
- per T lo e' quando inganna l'uomo, imitando il comportamento umano
- un computer che deve passare il test non eseguira' gli ordini direttamente, in quanto questi vanno filtrati rispetto alle capacita' di un umano
- =The Imitation Game=
* Comprensione
Output attesi $\implies$ comprensione? [[id:8c582ee0-1194-47b7-b6c9-9e46adaa60c7][John R. Searle]]
* Captcha
=Completely Automated Public Turing-test to tell Computers and Humans Apart=
Turing test inverso
* Strong & Weak
1. studio del pensiero e del comportamento umano, scienze cognitive
   + riprodurre l'intelligenza umana
2. risolvere problemi che richiederebbero intelligenza degli umani per essere risolto
   + non ci importa come l'umano ragiona, importa come risolvere il problema
   + task-oriented
* Agente - Environment
L'agente é immerso in un ambiente e svolge in ciclo esecutivo:
1. Percepisce
2. Delibera
3. Agisce

L'ambiente definisce cosa e' efficace e cosa non lo e'. questo in base agli /attuatori/ degli agenti possono essere posti in questo ambiente.
L'ambiente, in base a come si evolve nel tempo della percezione e deliberazione, puo' essere:
- statico
- dinamico

Inoltre si puo' distinguere un ambiente:
- deterministico
  + possibile prevedere in che stato un azione sposta l'ambiente
- stocastico
  + non e' possibile prevedere in tutti i casi lo stato in cui ci si trovera' dopo un azione
* Paradigma Dichiarativo
- imperativo: /how/, sequenza di passi
- dichiaritivo: /what/, si sfrutta una =knowledge base=
  + il cuore é il *Modulo dichiarativo* che utilizza l'informazione dalla percezione e la propria knowledge base
Quindi:
- un programma, risolutore, produce un altro programma che risolva una particolare istanza del mondo

* Automazione
Campo in cui l'informatico piu' in generale viene applicata
- automazione del calcolo
- automazione contabile
- automiazione della ricerca di informazione, motori di ricerca

Tratta di programmare un supporto a fare /ogni passo/, applicabile in domini fortemente ripetitivi
* Autonomia
Svolta da un agente artificiale che risolve un compito
- non viene indicato passo passi il modo per raggiungere l'obiettivo
- vengono forniti solo compiti ad alto livello

Utile nei problemi:
- non deterministici
- in cui c'e' molteplicita' di soluzioni
- con dati di natura simbolica
- si ha una conoscenza ampia e completa
- dove l'informazione e' parzialmente strutturata

* Agente Autonomo
- ha capacitá di /azione/
- riceve compiti ad alto livello
- esplora alternative, numero esponenziale di possibilitá da esplorare
- riconosce
  + se una strada non puó portare a una soluzione
  + un strada giá esplorata

Un =AA= rimane un programma, non fará ció che non é programmato a fare

Il cuore dell'agente é la funzione *deliberativa*
- un agente é /razionale/ se opera per conseguire il /successo/
- questo é possibile con una _misura di prestazione_ utilizzata come guida

La razionalitá ottimizza il risultato atteso
- possono intercorrere fattori ignoti o imprevedibili

* Risoluzione Automatica di Problemi
- nella realta' di riferimento si astrae utilizzando degli /stati/
  + astraendo si lascia solo una descrizione essenziale
  + discreti
  + tra questi ci saranno stati /target/ e stati di partenza
- la realta' transisce da uno stato all'astro tramite /azioni/
  + le azioni hanno effetto deterministico
- il dominio della realta' e' statico
- *l'algoritmo di ricerca* determina una soluzione
  + permette di raggiungere da uno stato iniziale uno stato target
    * una soluzione e' un percorso del grafo degli stati
  + utilizza:
    * descrizione del problema
    * metodo di ricerca

Fornendo una situazione iniziale e una situazione da raggiungere, appartenenti allo stesso dominio, l'agente deve trovare
una soluzione

* Problemi
Un problema puó essere definito formalmente come una tupla di 4 elementi
- Stato iniziale
- Funzione successore
- Test Obiettivo
- Funzione del costo del cammino

** Aspirapolvere
** Gioco del 15
Problema di ricerca nello spazio degli stati
- stato iniziale, qualsiasi
- funzione successore, spostamento di una tessera adiacente allo spazio vuoto nel suddetto
- test obiettivo, verifica che la stato sia quello desiderato (tabella ordinata)
- costo del cammino, ogni passo costa 1 e il costo del cammino é il numero di passi che lo costituiscono

*** Euristiche
- $h_1$ numero delle tessere fuori posto (rispetto alla configurazione goal)
- $h_2$ distanza di Manhattan
  + in particolare \[\sum_{\forall c}d_{\text{man}}(c)\]
** 8 Regine
Posizionare 8 regine su una scacchiera $8\times8$ in modo che nessuna sia sotto attacco
- generalizzabile con $N$ regine su una scacchiera $N\times N$

* Algoritmi
** Ricerca non informata - Blind
Costruiscono strutture dati proprie utilizzate nella soluzione di un problema
- alberi o grafi di ricerca
  + in un albero uno stato puó comparire piú volte


Ogni nodo rappresenta uno stato, una soluzione é un particolare percorso dalla radice ad una foglia
- i nodi figli sono creati dalla funzione successore
  + questi sono creati mantenendo un puntatore al padre

Gli approcci sono valutati secondo
- completezza
- ottimalitá
- complessitá temporale
- complessitá spaziale

Gli alberi vengono esplorati tramite =Ricerca in Ampiezza= e =Ricerca in Profonditá=

Nello studio di queste ricerche si considerano:
- $d$ profondita' minima del goal
- $b$ branching factor

Un goal a meno passi dalla radice non da' garanzia di ottimalita', in quanto vanno considerati i costi non il numero di passi.
Il costo e' una funzione monotono crescente in relazione alla profondita'.

*** Ricerca in Ampiezza
$O(b^{d+1})$
- complessitá sia spaziale che temporale
- esponenziale, non trattabile anche con $d$ ragionevoli
*** Ricerca Costo Uniforme
Cerca una soluzione ottima, che non in tutti i problemi corrisponde a il minor numero  di passi.
La scoperta di un goal non porta alla terminazione della ricerca. Questa termina solo quando non possono esserci nodi non ancora scoperti con un costo minore di quello gia' trovato.

La ricerca puo' non terminare in caso di =no-op=, che creano loop o percorsi infiniti sempre allo stesso stato.
Quindi:
$\text{costi} \ge \epsilon > 0$
- $\epsilon$ costo minimo

\[O(b^{1+\lfloor \frac{C^{*}}{\epsilon} \rfloor})\]
- $C^{*}$ costo soluzione ottima

*** Ricerca in Profondita' w/ Backtracking
Si producono successori su successori man mano, percorrendo in profondita' l'albero.
In fondo, in assenza di goal, viene fatto backtracking cercando altri successori degli nodi gia' percorsi.
- viene esplorato un ramo alla volta, in memoria rimane solo il ramo che sta venendo esplorato
- piu' efficiente in utilizzo della memoria

*** Ricerca in Profondita' w/o Backtracking
Si esplora espandendo tutti i figli ogni volta che viene visitato un nodo non goal
- viene utilizzato uno =stack= (=LIFO=)
*** Iterative Deepening
Ricerca a profonditá limitata in cui questa viene incrementata a ogni iterazione
- cerca di combinare ricerca in profonditá e in ampiezza
  + $\textsc{time}= O(b^d)$
  + $\textsc{space}= O(b\cdot d)$
  + completa
  + ottima quando il costo non é funzione decrescente delle profonditá
*** Ricerca Bidirezionale
2 ricerche parallele
- /forward/ dallo stato iniziale
- /backwards/ dallo stato obiettivo

Termina quando queste si incontrano a una intersezione.
Il rischio é che si faccia il doppio del lavoro e che non convergano a metá percorso ma agli estremi
- $\textsc{time}= O( b^{\frac{d}{2}})$
** Ricerca informata
Si possiedono informazioni che permettono di identificare le strade piú promettenti
- in funzione del costo

Questa informazione é chiamata *euristica*
$h(n)$: Il costo minimo stimato per raggiungere un nodo /preferito/ di $n$

*** Greedy
- costruisce un albero di ricerca
- mantiene ordinata la frontiera a seconda di $h(n)$

Ma l'euristica puó essere imperfetta e creare dei problemi.
Questa strategia considera solo informazioni /future/, che riguardano ció che non é ancora stato esplorato.
*** A*
Combina informazioni future e passate:
- *Greedy* e *Ricerca a costo uniforme*

Utilizza una funzione di valutazione:
$f(n) = g(n) + h(n)$

Dove $g(n)$ é il costo minimo dei percorsi esplorati che portano dalla radice a $n$

I costi minimi reali sono definiti con:
$f^{\star}(n) = g^\star(n) + h^\star(n)$
- definizione utilizzata nelle dimostrazioni

$A^\star$ é ottimo quando
- tutti i costi da un nodo a un successore sono positivi
- l'euristica $h(n)$ é ammissibile

*Ammissibilitá*
- $\forall n: h(n) \le h^\star(n)$
  + ovvero l'euristica é ottimistica

Nel caso di ricerca in grafi $h(n)$ deve essere anche *monotona consistente* per garantire l'ottimalitá
- vale una disuguaglianza triangolare
- $h(n) \le c(n,a,n') + h(n')$
- $\textsc{nb}$ tutte le monotone sono ammissibili ma non vale il viceversa

Inoltre é *ottimamente efficiente*
- espande sempre il numero minimo di nodi possibili
Ma $\textsc{space}=O(b^d)$

* Euristiche
** Calcolo della Bontá
Per decidere tra 2 euristiche ammissibili quale sia la piú buona
1. confronto sperimentale
2. confronto matematico

Si considera la *dominanza*
- $\forall n : h_2(n) \le h_1(n)\le h^\star(n)$
  + restituisce sempre valore maggiore rispetto all'altra
- una euristica dominante sará piú vicina alla realtá
Si puó costruire una nuova $h(n) = \max(h_1(n),\dots,h_k(n))$ dominante su tutte quelle che la compongono

Si valuta la qualitá dell'euristica (sperimentalmente) con il /branching factor/ effettivo $b^\star$
- si costruisce con gli $N$ nodi costruiti nella ricerca un /albero uniforme/
- $b^\star$ piccolo $\rightarrow$ euristica efficiente
