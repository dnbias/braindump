:PROPERTIES:
:ID:       77cc59df-765f-4523-a1d5-b937e581d8fc
:ROAM_ALIASES: ML
:END:
#+title: Machine Learning
#+date: [2022-09-21 Wed 20:39]
- Prof. Roberto Esposito, Prof.ssa Rosa Mao
- Peter Flach, /Machine Learning/, Cambridge University Press

* Ingredients of ML
- componenti necessari per la materia di studio
- Tasks
  - classificazione
  - regressione
  - stima probabilistica
  - clustering
    - capire la struttura dei dati
    - puo' anche essere un primo passo verso la classificazione
- Modelli
  - lineare
  - alberi di decisione
  - *naive bayes*
  - =KNN=
- Features
  - numeriche
  - categoriche
  - costruzione
  - selezione

Per predire la classificazione si cerca una $f(x)$ che date le features in input restituisca in output la classificazione che ci si aspetta dal learning set.

In un modello lineare abbiamo una /retta/ che _divide in un piano_ le entita' che appartengono a una categoria da quelli che non le appartengono

#+begin_quote
Machine learning is the systematic study of algorithms and systems that improve their knowledge or performance with experience.
#+end_quote

I task sono risolti dai modelli, i problemi di apprendimento sono risolti da algoritmi che /producono/ modelli.



* Tasks
- predittivo, l'obiettivo e' predirre una classificazione
- descrittivo, cerco informazioni in piu' sulla struttura del dataset
- classificazione binaria o multi-classe
- regressione, versione non discreta della classificazione
- clustering, target nascosto

Il =ML= puo' essere supervisionato o meno, quindi con etichette conosciute nel /learning set/

** Predictive ML
- input: dataset con le etichette assegnate
- cerchiamo un algoritmo di apprendimento che possa indurre un modello che riesca a fare predizioni su proprieta' in particolare degli esempi

Dipendentemente dalle etichette a da che proprieta' cerchiamo di approfondire e' possibile distinguere in:
- ranking
- scoring
- probability estimation
- regression


** Classification
Un classificatore e' un mapping:
\[\cap c: X \to C\]
dove $C = \{ C_{1} , \cdots , C_{k} \}$

$\cap c$ e' una approssimazione della reale (e sconosciuta) funzione $c$.
- e' possibile che un'istanza $x$ sia contaminata da rumore


*** Binary Classification
- *feature tree*, diverso dal *decision tree* in quanto nelle foglie ci sono esempi e non regole
- costruendo con gli esempi il feature tree e gli insiemi nelle foglie posso procedere assegnando una classificazione a ciascuna foglia
  - solitamente si procede ad assegnare come etichetta quella maggiormente rappresentata osservando le etichette degli esempi del /training set/

Apprendere un classificatore significa costruire la funzione $\cap c$ in modo che approssimi al meglio $c$ su tutto il set $X$ e non solo quello $x$ del training set.
- un esempio e' una coppia di un'istanza $x$ e della sua reale classe $c(x)$
- fatto questo si puo' valutare l'accuratezza, calcolata sul training set
  - questa misura puo' essere fuorviante
  - generalmente l'accuracy decresce al di fuori del training set
  - per questo il dataset viene diviso in training set e test set per evitare bias
    - il bias sul test set e' l'opposto, abbiamo un bias in difetto
    - quando il test set viene riutilizzato per un nuovo addestramento il modello migliorera' e quindi le stime precedenti saranno in difetto

**** Contingency Table
Tavola in cui vengono riportati
- true positives
- false negatives
- false positives
- true negatives

Contiene anche informazioni sui positivi e negativi del set.

Con questa tabella possono essere calcolate varie misure di *performance*:
- =TP=
- =TN=
- =FP=
- =FN=
- Proporzione di positivi
- Proporzione di negativi
- /class ratio/
- /accuracy/
- /error rate/
- /true positive rate/, /sensitivity/, /recall/
  - $TP/Pos$
- /true negative rate/, /specificity/
  - $TN/Neg$
- /precision/, /confidence/
  - $TP/(TP+FP)$

Classificatore troppo specifico significa /recall/ bassa, troppo generale significa /precision/ bassa.

**** Coverage Plot
Sulle assi =TP= e =FP=
- i classificatori che si posizionano sulla diagonale mediana sono i peggiori
- in alto a sinistra =ROC= heaven
- in basso a destra =ROC= hell

L'accuratezza e' la stessa per classificatori che giacciono su una stessa linea con pendenza 1
Punti sulla una linea parallela alla diagonale principale (pendenza $Pos/Neg$) hanno la stessa /average recall/
- $\frac{(TP/Pos)+(TN/Neg)}{2}$

**** Roc Plot
Gli assi vengono normalizzati, percentuale di =TP= e =FP=
- tpr - true positive rate
- fpr - false positive rate

Lo spazio di rappresentazione viene schiacciato in un quadrato, percio' le pendenze delle rette cambiano di conseguenza.
Per l'accuracy la pendenza delle rette diventa $Neg/Pos$
Per la avr recall la pendenza diventa 1

Gli errori sulle classi possono avere pesi diversi, questo puo' essere manipolando cambiando il ratio tra =FP= e =FN=.

**** Scoring Classifier
Una mappa:
\[s : X \to R^{k}\]

Gli score sono misure di confidenza del classificatore, le etichette nel dataset rimangono le classi.

Il *margine* e' una misura di confidenza, considerando $c(x)$ +1 per esempi positivi, -1 per esempi negativi:
- $z(x) = c(x) \cap s (x)$

E' desiderabile premiare grossi margini positivi e penalizzare grossi margini negativi.
Questo lo si ottiene con una *loss function*:
\[L : R \to [0, \infty )\]
- mappa ogni margine dell'esempio $z(x)$ con a un valore di *loss*

In molti casi l'apprendimento e' posto come un problema di ottimizzazione di _minimizzazione della funzione di loss_.
Ce ne sono di diverse:
- 0-1 Loss
- Hinge Loss
- Logistic Loss
- Exponential Loss
- Squared Loss

Il *ranking* e' indotto naturalmente dalla funzione di scoring
- il *ranking error rate* viene definito tra tutte e coppie positivo-negativo
  - si controlla se si sta dando un ranking errato (positivo con ranking minore del negativo) con 1 punto di penalita', mezzo punto in caso di ranking uguale
  - matematicamente si sta calcolando l'area al di sotto della curva =roc=
  - un *ranking error* di 1 significa che si e' sbagliato tutto

**** Class Probability Estimation
Classificatore di scoring che mappa:
\[p: X \to [0,1]^{k}\]

Assegnamo classe positiva se la probabilita' calcolata e' maggiore di 0.5 e viceversa per i negativi.
L'*errore quadratico*:
\[SE(x) = \frac{1}{2} || p(x) - I(x) ||_{2}^{2}\]
Questo errore si puo' calcolare su tutti gli esempi con la media aritmetica

E' spesso una buona idea eseguire uno /smoothing/ delle frequenze relative, il modo piu' comune per farlo e' la *Laplace correction*
\[p_{i} = \frac{n_{i} + 1}{|S| + k}\]

*** Beyond Binary


* Models
1. geometrico, si ragiona sullo spazio del problema per risolverlo
2. probabilistico, si cerca la probabilita' di appartenenza a una classe
   - *Naive Bayes*, modello piu' semplice possibile: assume che le features siano indipendenti
3. logico, i modelli sono definiti da espressioni logiche

L'obiettivo dell'apprendimento e' definire dei pesi che rendono corretta la predizione.

Se la probabilita' a priori di Y e' nota:
TODO
\[Y_{}_{\text{MAP}} &= \text{arg max } P(Y|X) \\ \text{arg max } P(Y|X)\]

Altrimenti:

** Linear Models

** Ensamble Learning

* Features
Strumenti con cui descriviamo gli oggetti del dominio
- anche la granularita' con cui vengono aggregate le feature puo' cambiare la chiarezza del trend e puo' aiutare l'algoritmo di apprendimento.
- le features possono essere mappate a nuovi spazi, semplificando lo spazio cui e' possibile applicare un modello lineare per classificarlo piu' semplicemente

* Find-S
1. iniatialize $h$ to most specific hypothesis $\in H$
2. /for each/ =positive= instance $x$ in training
   - /for each/ constraint $a_{i} \in h$
     - if $a_{i}$ satisfied by $x$, =noop=
     - else, replace $a_{i}$ in $h$ with the next most general costraint that is satisfied by $x$
3. output hypothesis $h$

Proprieta':
- Descrive lo spazio delle ipotesi come congiunzioni di attributi
- restituisce l'ipotesi piu' specifica consistente con gli esempi positivi nel =TS=
- l'output sara' consistente anche con gli esempi negativi se il concetto target e' contenuto in $H$
- l'algoritmo non comunica se si e' arrivati al concetto obiettivo, non e' in grado di individuare se quella trovata e' l'unica possibile
- non guardando gli esempi negativi e' possibile che non si accorga che il dataset sia inconsistente
- l'ipotesi piu' specifica e' preferibile?
  - maggiori vincoli vogliono dire piu' informazioni sull'ipotesi
  - l'ipotesi piu' generale ha maggiore capacita' rappresentativa

* Version Space
L'output di =Find-S= e' una delle ipotesi valide consistenti con i dati
- l'insieme di queste ipotesi e' il =Version Space=
- l'insieme puo' essere molto grande, serve un algoritmo che non ne enumeri gli elementi
  - rappresentazione compatta

#+begin_quote
The *Version Space* $VS_{H,D} with respect to hypothesis space $H$ and training set $D$ is the subset of hypothesis from $H$ consistent with al training examples:
\[VS_{H,D} = \{h \in H | \text{Consistent}(h,D)\}\]
#+end_quote

Un dataset piu' grande permette di individuare un =Version Space= piu' piccolo, eventualmente di individuare l'ipotesi corretta.

Agli estremi del =VS= si individuano due sottoinsiemi, $G$ - /general boundary/ - le ipotesi piu' generali, $S$ - /specific boundary/ - le ipotesi piu' specifiche. Quindi:
\[VS_{H,D} = \{h \in H | (\exists s \in S)(\exists g \in G)(g \ge h \ge s)\}\]
- $\ge$ means =is more general or equal than=
- questa rappresentazione e' molto piu' compatta
- gli esempi positivi muovono $S$ in basso
- gli esempi negativi muovono $G$ in alto
- assieme queste operazioni restringono $VS$

** List-Then Eliminate
1. =VersionSpace= $\gets$ lists of every hypothesis in $H$
2. /for each/ training example
   - remove hypothesis that are inconsistent with training example
3. output =VersionSpace=

** Candidate Elimination
1. $G \gets$ maximally general hypothesis in $H$
2. $S \gets$ maximally specific hypothesis in $H$
3. /for each/ training example $d = \langle x, c(x) \rangle$
   - $d$ positive
     - remove from $G$ hypothesis inconsistent with $d$
     - /for each/ hipothesis $s \in S$ inconsistent with $d$
       - remove $s$ from $S$
       - add to $S$ all minimal generalizations $h$ of $s$ such that $h$ consistent with $d$ and some member $G$ is more general than $h$
       - remove from $S$ hypothesis more general than another member in $S$, maintain /minimality/
   - $d$ negative
     - remove from $S$ hypothesis inconsistent with $d$
     - /for each/ hypothesis $g \in G$ inconsistent with $d$
       - remove $g$ from $G$
       - add to $G$ all minimal specialisations $h$ of $g$ such that $h$ consistent with $d$ and some member $S$ is more specific than $h$
       - remove from $G$ hypothesis less general than another member in $G$

L'apprendimento termina individuando la singola ipotesi che descrive correttamente il concetto ricercato oppure a causa di inconsistente nel dataset lo rimuovera', convergenza all'insieme vuoto.
*L'ordine di presentazione degli esempi non e' importante per la convergenza.*

** Restringere lo spazio delle ipotesi
- si cerca di chiedere esempi all'oracolo che siano il piu' informativi possibile
  - generalmente si cerca di massimizzare il *valore atteso*
  - si cerca di eliminare sempre meta' delle ipotesi possibili

** Biased Learner
Per la classificazione (/previsione/) di nuovi dati si va per voto
- se tutte le ipotesi nello spazio sono tutte soddisfatte si assegna all'esempio l'etichetta positiva
  - viceversa per il negativo
- se le ipotesi non sono concordi nella classificazione e' da decidere come comportarsi con quell'esempio, in quanto c'e' un dubbio

Ma il nostro spazio delle ipotesi non puo' rappresentare /concept/ anche di poco piu' complessi
- disgiunzioni ad esempio

Lo spazio delle ipotesi e' *biased*, in quanto costruito con linguaggio congiuntivo.

** Unbiased Learner
Si espande lo =HS= al *power set* delle features.
- permette di esprimere un numero molto piu' grande di ipotesi
- esprime /target concept/ in logica piu' complessa

Il problema e' che le ipotesi specifiche *S* e quelle generali *G* sono troppo specifiche o troppo generali, andando a modellare solo gli esempi nel =TS=
- per imparare il /target concept/ sarebbe necessario presentare ogni istanza nell'insieme modellato come training example

Il *bias* quindi non e' un limite, permette di fare l'*inductive leap*. Permettendo la generalizzazione dei concetti imparati dal =TS=.

** Inductive Bias
Il sistema di apprendimento automatico si puo' costruire come sistema induttivo *equivalente* a un sistema puramento deduttivo come un /Theorem Prover/.
Per cui il concetto rappresentato viene come conseguenza logica dalle ipotesi specifiche del /learner/.
