#+TITLE: Sistemi Operativi
#+COURSE: SO A
#+PROF: Davide Gunetti ~ Daniele.Gunetti@unito.it
#+STARTUP: latexpreview
[[file:#universita.org][#universitá]]

* Generalita'
2 obiettivi di un OS:
- utente: rendere il sistema semplice
- macchina: rendere il sistema efficente e sicuro

- fornisce strumenti per uso corretto e semplice da usare
- Alloca risorse in maniera conveniente
- Controlla l'esecuzione dei processi per evitare pericoli

** Confine OS - Software

*** GUI all'inizio non parte del OS
Con Windows viene integrata

*** Comandi Shell
La shell non e' parte OS in Unix

** Kernel
E' il cuore del PC
gestisce
- programmi in esecuzione
- memoria principale
- memoria secondaria

** Gestione Eventi
*** L'OS generalmente non sta utilizzando le risorse
**** le gestisce e le fa usare ai programmi
**** puo' essere chiamato in causa dai programmi
<<<<<<< HEAD
        :PROPERTIES:
:ID:       98593566-3de2-4cb9-88c0-dafc002bed8a
:END:
=======
>>>>>>> 74e75ebd8fe4cc2f57b733ba168b84613c120970
*** puo' controllare che tutto sia in ordine
*** Interruzioni
Evento --> OS gestisce l'evento prendendo il controllo della macchina
- una volta gestito e' restituito il controllo ad uno dei programmi che stavano girando prima dell'evento
*** Interrupt
natura hardware
- segnali che richiedono intervento OS
*** Eccezioni
natura software
- causate dal' programma in esecuzione
  divese in
**** Trap
tentata divisione per 0
tentato accesso ad area protetta
**** System Call
richiesta di eseguire un operazione su un file
*** CPU segue dei passi predefiniti a livello hardware
- Salva lo stato della computazione
  + PC e altri valori della CPU in appositi registri
  + permette il riavvio del programma al punto di gestione evento
- in PC si scrive l'indirizzo in RAM della porzione di codice del OS che gestisce l'evento verificatosi
  + in =BootStrap=
    - OS carica in RAM
      + vettore delle interruzioni
        - ~n~ puntatori che indicano l'inizio dei codice di gestione eventi

      + Codice gestione evento ~n~
- return from event
  + ultima istruzione di ogni procedura di gestione
  + riprende l'esecuzione del programma precedente
** Struttura della Memoria
*** Principale - RAM
La memoria indirizzata alle istruzione eseguite
*** Secondaria - di Massa
Risiedono qui permanentemente dati e programmi
La gerarchia di memoria
- le memoria sono sempre piu' veloci ma di costo maggiore
- da fissse diventano volatili
- la componentistica per bit occupa piu' spazio
  + da condensatori passiamo ai Flip-Flop nei registri

La gerarchia di memorie e' una gerarchie di =Cache= di una rispetto alla precedente
- la RAM fa da cache per l'HD
  + le istruzioni di un programma sono copiate da HD a RAM per essere eseguite
- la Cache fa da cache per la RAM
- I Registri fanno da cache per la RAM
** Struttura di I/O
CPU connessa a dispositivi di I/O
- connessi da BUS
  Ogni dispositivo e' controllato da un =controller= hardware
  - ogni controller e' un piccolo processore
    + con
      - registri
      - memoria interna
        + =buffer=
          - dove il controller tradferisce i dati del dispositivo
  - OS interagisce con il controller
    + attraverso software:
      - =driver=
    + specifica nei registri del controller le operazioni da compiere
      - il controller eseguira' quello che gli e' specificato
      - una volta completato invia ~interrupt~ al driver
        + OS riprende il controllo

    Questa gestione e' adeguata solo per piccole quantita' di dati
    - inefficiente per moli maggiori
    - per inviare interi blocchi di dati dal controller al RAM
      + =DMA= Direct Memory Access
        - canale diretto tra dispositivo e RAM
        - OS tramite driver istruisce
          + prendi blocco numero n su HD e trasferisci in RAM a partire dalla locazione di indirizzo xxxx
** Multitasking & Time-sharing
*** Multitasking
Mantenere in memoria principale piu' programmi insieme ai dati di questi in modo da aumentare la ~produttivita'~
- quando un programma si ferma temporaneamente (per eseguire operazioni di I/O) l'OS ha gia' in RAM un secondo programma a cui assegnare la CPU
  + =job=

*** Timesharing
- interattivita'
- sistemi multi utente
  In caso la CPU non abbia tempo di idle durante l'esecuzione dei programmi
  - Il tempo di CPU sara' distribuito tra gli utenti e i loro programmi
    - da' l'impressione di simultaneita' (solamente apparente)
** Modalita' di Funzionamento
*** Doppia Modalita'
- Specificata da un bit di modalita'
- Esistono istruzioni protette che sono eseguibili solo in modalita' di sistema (quindi dall'OS)
  - i programmi utente usano le =system call= per operazioni che richiedono l'esecuzione di istruzioni privilegiate
    - l'OS gestisce e poi restituisce il controllo all'utente
  - realizzate attraverso eccezioni che cambiano il bit di modalita'

**** Normale
**** Sistema | Kernel | Monitor | Supervisor
*** Timer
~for(;;)i++;~  ciclo che non termina mai
- Per questi casi e' disponibile in CPU un Timer, dopo un certo tempo inizializzato dal OS viene inviato un =interrupt=
  - utilizzato anche in caso di Time Sharing
  - il timer e' gestito con istruzioni provilegiate
    - per evitare usi impropri malevoli
*** Protezione della Memoria
Evita la sovrascrittura delle aree di memoria di programmi in RAM da parte di altri programmi in esecuzione
- Soprattutto le aree dedicate all'OS
- Due registri in CPU
  - base
  - limite
    Ogni indirizzo generato dal programma in esecuzione viene confrontato con i valori contenuti nei registri
    - se non contenuto viene generata una =Trap=

** Strutture dei Sistemi Operativi
Livelli di complessita' e di accesso
- alcuni sono invisibili agli utenti
*** interfaccia col sistema operativo
non fa parte del kernel, ma e' fornito insieme all'OS
- interpreti di comandi | shell Unix
  - comandi == eseguibili
- GUI - interfaccia grafica
  - prima diffusione commerciale - ~1984~ Macintosh

*** programmi/servizi di sistema
non fanno parte del kernel, ma forniti insieme all'OS
rendono piu' semplice l'uso del sistema
- editor
- compilatori
- assemblatori
- debugger
- interpreti
- IDE
- browser
- gestori di email

*** chiamate di sistema
processo == programma in "esecuzione"
- un processo deve compiere una operazione privilegiata
  + System Call
- le system call sono la vera interfaccia tra processi e OS
  + procedure inserite in programmi scritti in linguaggi di alto livello
  + sembrano normali subroutine ma l'esecuzione e' portata avanti direttamente dal'OS
- esempi:
  + open() ~restituisce file descriptor~
  + write()
  + close()
  + fork()
- API
  + Application Programming Interface
  + strato intermedio tra applicazioni e system call
    - semplificano l'uso e la portabilita'
  + Api Windows / Api POSIX
  + esempi:
    - fopen() ~restituisce file pointer~
    - fprintf()
    - fclose()

*** gestione dei processi/memoria primaria/memoria secondaria
- =Processi concorrenti=
  + Competono per
    1. CPU
    2. spazio in memoria
    3. dispositivi INPUT/OUTPUT
- Gestione dei processi
  - Creazione | fork()
  - Sospensione e Riavvio
  - Sincronizzazione
  - Comunicazione
- Gestione Memoria Primaria
  - un programma in esecuzione e' caricato in memoria primaria (vedi Memoria Virtuale)
  - Time-Sharing
    - tenere traccia delle aree di RAM utilizzate e da che processo
    - distribuzione della RAM tra i processi
    - gestione dinamica della RAM
- Gestione Memoria Secondaria | File System
  - informazioni del sistema contenute in un =file=
  - file organizzati in una struttura gerarchica
    - =File System=
  - strumenti del OS
    - creazione
    - cancellazione
    - gestione file e directory
    - memorizzazione efficiente

*** protezione e sicurezza
Ogni processo deve essere protetto dalle attivita' improprie degli altri processi
- non deve essere possibile impadronirsi di una risorsa in modo esclusivo
- non devono essere accessibili aree di memoria assegnate ad altri processi

  Nessun utente puo' accedere a file di altri utenti

  =Macchine Virtuali=
  - ogni utente usa la VM indipendentemente dell'hardware
  - l'utente ha l'illusione di avere una CPU, un File System
    - nella realta' le risorse sono condivise

** Problemi

1) tener tracciatutti i programmi attivi nel sistema
   - stanno usando la CPU
   - richiedono l'uso della CPU
     - =processi= =thread=
2) CPU libera: a quale programma in RAM assegnare la CPU
3) interazione tra programmi senza danneggiarsi
   * evitare stallo
   * problemi di =sincronizzazione=
4) gestione della RAM
   * traccia delle aree di memoria occupate e da che programma
     * =memoria centrale=
     * =memoria virtuale=
5) gestione del File System
   * memoria di massa
   * fornire un'interfaccia
   * implementare il file system

** NB
- Single/Multi-Core
  + '90 CPU == singolo
    - un unico programma poteva utilizzare piu' CPU
    - sistema multiprocessore
      + tutti i processori condividono un'unica memoria principale
      + UMA
  + 2000
    - l'aumento delle prestazioni rallenta sensibilmente
    - processori costituiti da 2 processori affiancati sullo stesso _Die_
      + 2 Core
      + Processore Dual-Core
    - piccoli sistemi UMA
      + tutti i core possono indirizzare la stessa memoria principale
      + si condivide anche un livello di cache (L3) solitamente
- Non esiste una grande differenza tra OS per single-core o multi-core
  + in questo corso si presume che esiste un'unica unita' di calcolo
- OS di Rete e OS distribuiti

* Gestione Processi, Sincronizzazione
Componente del OS: =CPU Scheduler=
- Sceglie processi in coda di ready
- si attiva ogni 50/100 secondi
  - crea ~overhead~

** Processi
Unita' di lavoro del OS
- il primo ruolo del OS e' amministrare i processi
  - creazione
  - cancellazione
  - scheduling dei processi
  - sincronizzazione e comunicazione
    Un processo non e' solamente un programma in esecuzione
    - Struttura in Memoria =immagine del processo=
      - Codice
      - dati
      - stack
      - heap
    Un programma puo' definire piu' processi
    - un programma puo' contenere codice per generare piu' processi
    - piu' processi possono condividere lo stesso codice
    Fondamentalmente:
    - processo: entita' =attiva=
    - programma: entita' =statica=
    Un processo nasce sempre a partire da un'altro processo attraverso una opportuna =System Call=


*** =Stati= di un processo
L'OS sposta il processo tra vari stati attraverso cui esso evolve
- ~New~
  - Va assegnato ~Process Control Block~ e ~spazio in memoria~ necessario per il codice e i dati
  - questo e' gestito con interrupt, l'OS deve controllare subito perche' non conosce la naturea dell'interrupt e non puo' lasciare finire un processo in Running
- ~Ready~ (to run)
  - Scheduler Dispatch - componente del OS che sceglie e lancia il processo
  - Ci sono livelli di priorita' per i processi
    - un processo a bassa priorita' potrebbe rimanere in attesa del suo turno per sempre
- ~Running~
  - L'OS gira nel tempo tra un processo e l'altro, altrimenti sta in attesa (sleeps)
  - Se piu' processi: dopo un determinato tempo l'OS prende il controllo inviando un =interrupt=
    - il tempo di esecuzione puo' essere interrotto da interrupt ma verra' poi restituito subito dopo al processo in questione
- ~Waiting~
  - Il processo puo' aver richiesto una operazione di I/O (con una System Call)
    - queste operazioni sono sotto il controllo del OS, quindi sara' questo a interrompere il Waiting una volta completate
- ~Terminated~
  - Il processo termina
  - L'OS riprende il controllo per ripulire la memoria dall'area occupata dal processo ora terminato
**** =diagramma= di transizione degli stati di un processo
- Rimuovere l'arco interrupt
  - da' il diagramma di un OS multitasking ma non time-sharing

*** Process Control Block - =PCB=
- Process ID
- Stato
- Contenuto dei registri della CPU una volta sospeso il processo
- Indirizzi RAM aree dati e codice
- File in uso
- Informazioni Scheduling

  E' il PCB del processo che viene inserito in coda di ready dopo che l'OS ha recuperato il codice e caricato in RAM

#+NAME: Crezione di un processo in Unix
#+BEGIN_SRC C
int main(){ //NB: ad un programma possono corrispondere piu' di un processo
    pid_t pid, childpid;
    pid = fork(); //genera un nuovo processo copiando codice e dati del padre,
                  //nel PID indica gli indirizzi che lo riguardano
                  //nella cella di memoria del PID padre scrive il PID del figlio
                  //nella cella di memoria del PID figlio scrive 0
    printf("questa la stampano padre e figlio"); //sia padre che figlio riprendono dopo il fork
    if(pid == 0){
        printf("processo figlio");
        execlp("/bin/ls", "ls", NULL); //specifica il codice da eseguire, NB non ritorna
    }
    else{ //eseguito dal padre in quanto in pid contiene un numero maggiore di 0
        printf("sono il padre, aspetto il figlio");
        childpid = wait(NULL); //Waiting Queue, i due processi si sincronizzano
                               //a processo figlio terminato viene scritto il PID figlio
                               //a questo punto il padre viene reintrodotto nella Ready Queue
        printf("il processo figlio e' terminato");
        exit(0);
    }
} //System Call: fork(), execlp(), wait(), exit()
#+END_SRC
Il codice e' copiato solo concettualmente, le aree dati sono realmente duplicate
- System Calls utili
  - getpid()
    - restituisce il process Id del processo chiamante
  - getppid()
    - restituisce il process Id del parent del processo chiamante

*** Operazioni su processi
**** Creazione
- ogni OS possiede almeno una ~System Call~ di creazione
  - tutti i processi nascono da altri processi ~con l'eccezione~ di quello all'accensione del Sistema
- nel sistema si forma un =albero di processi=
  - Il Creatore e' detto Padre - =parent=
  - Il Creato e' detto Figlio  - =child=

    Nel Creare un albero l'OS riferisce i processi con un ~PID~ (Process ID) ovvero un identificatore
    - Comando:
      - ps - process status

#+SOURCE-START
***** Scelte ingenieristiche
Moderni OS implementato tutte queste combinazioni nelle loro System Call
****** Avvio
******* Processo padre continua concorrentemente al figlio - ready queue
******* Processo padre di ferma attendendo l'esecuzione del figlio - waiting queue
****** Esecuzione
******* Fornire al figlio copia del codice padre
******* Nuovo programma al figlio
**** Uccisione
- kill / TerminateProcess(Win)
  - secondo PID
  - puo' avvenire se =TRAP=

*** Comunicazione tra processi

**** indipendenti

**** cooperanti
si influenzano l'un l'altro
- si scambiano informazioni
- portano aventi una elaborazione suddivisa
  Per permettere cio' l'OS deve mettere a disposizione meccanismi appositi

***** Inter-Process Communication =IPC=
L'OS mette a diusposizione System Call volte all'implementazione di:
- memoria condivisa
  - sovrascritto il divieto della memoria dell'altro processo
  - Scelte  implementative
    - dimensione variabile?
    - che processi hanno diritto di uso?
    - un processo

- scambio di messaggi
  - coda di messaggi
    - gestita dal OS
      - Scelte implementative
        - coda usata da piu' di due processi?
        - limite alla dimensione della coda?
        - ricevente se non ci sono messaggi? sospensione?
        - trasmittente se la coda e' piena?  sospensione?
    Esempi di System Call
    - msgget()
    - send(message, line, PID)
    - receive(message, line, PID)

****** Pipe

****** Client-server

******* Socket

******* Remote Procedure Call =RPC=

***** esempio
processo =produttore=, produce informazioni utilizzate da un processo =consumatore=
- informazioni poste in un =buffer=

  =produttore=  - Compilatore  ~ produce codice oggetto
  =consumatore= - Assemblatore ~ consuma codice oggetto

#+BEGIN_SRC C
#define SIZE 10
typedef struct {...} item;
item buffer [SIZE];
int in = 0, out = 0;
#+END_SRC
in: prossimo item libero
out: primo item pieno
buffer vuoto: in=out
buffer pieno: in+1 mod SIZE = out --il buffer e' utilizzato in modo circolare
NB: Il buffer pieno usera' ~SIZE-1 posizioni~
#+NAME: Consumatore
#+BEGIN_SRC C
item nextp;
repeat
while (in == out) // empty buffer
    do no_op;
nextp = buffer[out];
out = out+1 mod SIZE;
<consuma l'item in nextp>
until false;
#+END_SRC

#+NAME: Produttore
#+BEGIN_SRC C
item nextp;
repeat
<produci nuovo item in nextp>
while(in+1 mod SIZE == out) // full buffer
    do no_op;
buffer[in] = nextp;
in = in+1 mod SIZE;
until false;
#+END_SRC

** Thread

** Scheduling
Presupponendo un sistema Single-core
L'OS fa credere ai processi di avere tutta la CPU per loro
- Process Switch/Context Switch
  - L'=unico= PC viene aggiornato con i valori relativi al processo Running

    NB: Diagramma di Gantt

*** Context Switch
Passaggio da un processo in esecuzione all'altro
=Commutazione= della CPU tra i processi
- OS prende il controllo CPU ~ questo e' tecnicamente pure un Context Switch
- Salva lo stato della computazione del processo uscente in PCB
- Scrive in PC e nei registri CPU i valori PCB del processo entrante

  Questa operazione richiede tempo: ~overhead~ di sistema (sovraccarico)

*** Code di Scheduling
OS gestisce varie code di processi
- una lista di =PCB=

- Coda di Ready ~ Ready Queue ~ =RQ=
  - coicide con lo stato Ready nel ~diagramma~

- n Code di Waiting
  - Code dei dispositivi ~Device Queues~
    - piu' processi possono essere in coda per l'accesso ad un dispositivo
  - Code di Eventi       ~Waiting Queues~

**** Diagramma di accodamento
riformulazioe del diagramma di transizione prendendo in considerazione le code

*** Implementazione
Tecniche per massimizzare la produttivita' della CPU
- [[Multitasking]]
- [[Time Sharing]]
  Per cio' devono essere definite delle regole dal progettista

  I processi vivono fasi di ~CPU-burst~ e ~I/O-burst~
  I processi possono essere
  - CPU-bound
    - un compilatore x es
  - I/O-bound
    - un browser
    - un editor

**** Scheduler
decide quale processo in coda di ready sara' eseguito quando:
1. il processo in esecuzione passa volontariamente in stato di waiting
2. il processo in esecuzione termina
3. il processo in esecuzione viene ~obbligato~ a passare allo stato di ready
   - questo con un timer hardware - =vettore delle interruzioni=
4. un processo \(P_x\) entra in coda di ready arrivando da un coda di wait oppure e' sato appena lanciato
   1) l'OS interviene per gestire il =PCB= di \(P_x\) spostandolo in coda di ready
   2) se \(P_x\) e' piu' importante del processo in esecuzione

      per 1. 2. e' sufficiente un OS multitasking

**** Dispatcher
- implementa il [[Context Switch]]
- passa in user mode
- ripristina il PC della CPU alla corretta locazione

**** senza diritto di prelazione
=non-preempive scheduling=
Casi 1. e 2.
- I processi non posso interrompere l'esecuzione di altri processi

  Implementazione piu' snella utilizzata per OS specifici
**** con diritto di prelazione
=preemptive scheduling=
Casi 1. 2. 3. e 4.
- I processi non possono eseguire a tempo indeterminato
- I processi possono avere priorita' diverse

  Implementazione utilizzata per OS general purpuse

  Se una =System Call= chiamata dal processore in esecuzione viene ~interrotta dal vettore di interrupt~?
  - la prima istruzione della System Call puo' essere un'istruzione che
    - ~disattiva gli interrupt~
  - ultima istruzione
    - ~riabilitazione degli interrupt~

**** Criteri
Obiettivi:
- massimizzare =uso CPU=
- massimizzare il =Throughput=
  - ovvero la produttivita'
  - minimizzare il =tempo di risposta=
    - importante per i processi interattivi
- minimizzare il =Turnaround time=
  + tempo medio di completamento di un processo
    + da quando entra per la prima volta in coda di ready fino a quando non termina l'esecuzione in stato running
      - per semplificare non si considera la creazione e la terminazione del processo
- minimizzare il =Waiting time=
  + somma del tempo passato dal processo in ~coda di Ready~

~Turnaround Time~ = WaitingT + RunningT

**** Algoritmi
Considerando in questo corso processi con un =unico burst di CPU= e =nessun burst di I/O=

Un Algoritmo tanto é migliore quanto le sue prestazioni di avvicinano da =SJF= allontanandosi da =FCFS=

~def~
***** Starvation
+ il processo non viene mai scelto in quanto mai di prioritá
  * Aging
    + il processo aumenta di prioritá con il tempo passato in RQ

***** First Come, First Served
=FCFS=
***** Normale coda FIFO
+ PCB inserito in fondo alla coda
+ CPU libera assegnata al primo PCB alla testa
****** Non-preemptive
+ non implementa time-sharing
******* Tempo di attesa elevato
+ Effetto convoglio ~ accodamento job piu' corti

  Osservazioni
  - sfavorisce i processi brevi
  - non implementa sistemi time-sharing

  Peggiore degli Algoritmi ragionevoli

***** Shortest Job First
=SJF= ~ Shortest Next CPU Burst
- Esamina la durata del prossimo burst di CPU dei processi in RQ
- assegna la CPU al processo con burst minimo
- Puó essere ~preemptive~ o ~non-preemptive~
  1) Preemptive - =Shortest Remaining Time First= =SRTF=
     + se in RQ é presente un processo il cui ~CPU-burst é minore del tempo di esecuzione rimanente~ al processo Running, ha la priorita' il nuovo processo e viene interrotto quello in stato Running
       + Ipotesi solamente teorica

     É dimostrabile che SJF é ~ottimale~
     + spostando un processo breve prima di uno lungo
       - si migliora l'attesa del processo 1 piú di quanto di peggiori l'attesa del processo lungo
         + quindi diminuisce alche il Turnaroud-time medio

     ~MA~
     la durata del prossimo burst di CPU non é nota
     + SJF non é implementabile

***** Priority scheduling
=PS=
calcolo della prioritá:
- interna al sistema
  + sulla base di ogni processo
- esterna al sistema
  + sulla base del utente
    Puó essere ~preemptive~ o ~non-preemptive~



***** Round Robin
=RR=
L'algoritmo di implementazione del time-sharing, la RQ e' utilizzata come una coda circolare
- ogni processo ha un ~quanto di tempo~ implementato da un timer hardware che invia un interrupt allo scadere del tempo
  + entro il suo tempo il processo non lascia la CPU se non per wait
  + alla fine del suo tempo il processo é interrotto
- il prossimo processo ad andare in esecuzione sará il primo in RQ
Con \(n\) processi in coda di ready e il quanto di tempo \(q\) ogni processo riceve \(1/n\) del tempo della CPU e nessun processo aspetta piú di \((n-1)q\) unitá di tempo

- Turnaround medio peggiore di SJF
  + ovviamente
- Tempo di risposta medio migliore di SJF


Prestazioni dipendenti da \(q\):
- \(q \to\infty\)
  + RR == FCFS
- \(q\to 0\)
  + aumenta l'illusione di ~parallelismo~
  + aumenta il numero di ~context switch~

- regola empirica
  + \(80\% \text{ dei CPU burst} < q\)


***** Multilevel Queue
=MQ=
Code multiple
- foreground -- RR
  + interagiscono con l'utente
- background -- FCFS
  + non interagiscono
- batch
  + la loro esecuzione puó essere differita

Si puó suddividere la RQ in piú code
+ gestire ogni coda con un algoritmo ottimale
+ Scelta:
  - prioritá fissa
    - possibile starvation
    - time slice
      - quanti di tempo maggiori per foreground, minori per background  e batch

***** Multilevel Feedback Queue
=MFQS=
Code multilivello con retroazione
- I processi possono essere promossi a code a piu' alta prioritá o retrocessi
- assegnamento a coda dinamico
  - i processi sono spostati dal OS per
    + adattarsi alla lunghezza del CPU burst
    + gestire ogni coda con lo scheduling adatto rispetto al comportamento mostrato

- Es
  - se il processo esaurisce il quanto assegnato dalla prima coda RR, sara' spostato alla coda RR successiva con un quanto maggiore
  - se il processo esaurisce i quanti delle code RR sará spostato in una coda FCFS

**** Multielaborazione Simmetrica
=SME=
- scheduler per ogni core
  + code condivise
    + sincronizzazione
- code private ai core ~ preferita dagli OS moderni
  - necessario un sistema di bilanciamento tra le RQ dei core
    + difficoltá dovute a cache a piú livelli
      - dati e istruzioni di un processo sono man mano indirizzati e copiati nei vari livelli di cache
      - se spostato su un'altro core le informazioni vanno recuperate in quanto contenute in cache private di un altro core
        +
      - OS possono relegare un processo particolare ad un unico core per questo motivo



*** Esempi di Scheduling

*** Solaris
    - Scheduling a code multiple con retroazioine
      1. real time
      2. sistema
      3. interattiva
        - 60 livelli di prioritá - 50-59
      4. timesharing
        - 60 livelli di prioritá - 0-40

    Di norma i processi nascono nella classe _timesharing_
    I processi seguono prioritá formattate cosí:
    | Priority | Quantum[m/s] | New priority (exhausted quantum) | New priority (unexhausted) |
    |        0 |          200 |                                0 |                         50 |
    |      ... |          ... |                              ... |                        ... |
    |       59 |           20 |                               49 |                         59 |

    I processi possono essere promossi o meno in base al quanto che hanno sfruttato
    - maggiore é la prioritá maggiore é la probabilitá che verrá scelto per l'esecuzione al prossimo ciclo ma minore sará il quanto a lui assegnato dal OS
    Processi di sistema e real time hanno prioritá fissa, maggiore di interattiva e time sharing
    - lo scheduler calcola la prioritá globale di un processo
      + prioritá == si usa RR
      + algoritmo preemptive

*** Windows
    Prioritá con retroazione e prelazione
    - 32 livelli
      + real time - 16-31
      + altri - 1-15

    Lo scheduler sceglie il processo a prioritá piú alta
    - se il processo va in wait
      + viene alzata la sua prioritá
        - dipendentemente dalla tipologia del wait
          + se é atteso un dato dal disco l'aumento é minore
    - in caso di prioritá uguale é utilizzato il RR
      + se il quanto viene esaurito la sua prioritá é abbassata
        - limite 1
    Favorisce i processi che interagiscono con mouse e tastiera
    Inoltre W distingue tra background e foreground
    - il processo foreground ottiene 3 volte l'aumento del quanto di tempo che gli altri processi

*** Linux
    Completely Fair Scheduler =CFS=
    Cerca di distribuire a tutti i processi equamente il tempo di CPU

    Ad ogni context switch lo scheduler calcola il quanto tempo che spetta ad un processo P in modo che tutti i processi abbiamno avuto la stessa quantitá di tempo di CPU
    - P.vruntime = P.expected_run_time - P.due_cputime
      - CPU data al processo con P.vruntime piú basso
        - CPU-use minore
    - i processi ready-to-run sono nodi di un albero di ricerca bilanciato: =red-black tree= o R-B tree
      + permette operazioni molto efficienti
        - O(logx)
      + i nodi sono inseriti con la chiave del P.vruntime
        - il nodo piú a sinistra sará quello scelto dallo scheduler


** Sincronizzazione
<<<<<<< HEAD
    I processi possono cooperare, perció dovranno condividere dei dati
    - é necessario evitare la creazione di ~dati inconsistenti~

    Devono sincronizzarsi
    ~Problema~
    - mentre P1 elabora dati che verranno usati da P2 viene rimosso dall'esecuzione
      + P2 non dovrá lavorare sui dati incompleti lasciati da P1

    - esempio
      + produttore - consumatore
        - utilizzata variabile condivisa buffer/counter (buffer circolare)
          - se produttore esegue counter++ 'mentre' consumatore esegue counter--

            + questo puó verificarsi perché quella eseguita non é una operazione ~atomica~, non utilizzano una sola istruzione ISA a livello di architettura

    La sincronizzazione é un problema solamente se si effettuano scritture su memoria condivisa
    - le operazioni da sincronizzare devo concludersi completamente e non essere interrotte dallo scheduler per passare al processo sincronizzato dati consistenti
    Va sviluppato un protocollo usato dai processi che vanno ad usare variabili condivise
    Il codice sará strutturato in questo modo:
                    =entry section=
      - richiesta di entrare nella sezione critica
                   =sezione critica=
                     =exit section=
      + segnalazione di uscita dalla sezione critica

    Una soluzione al problema avrá queste proprietá
    - Mutua Esclusivitá
      + mai ci saranno conflitti di accesso
    - Progresso
      + se la sezione critica non sta venendo eseguita allora un processo in futura ne avrá accesso
      + questo garantisce l'assenza di =deadlock=
    - Attesa Limitata
      - qualsiasi processo che richiede di accedere alla sua sezione critica non soffrirá di =starvation=
      - evitare attese infinite

    Una soluzione corretta deve permettere ai processi di computare indipendentemente dalla loro velocitá
    - non deve dipendere dallo scheduling del sistema


*** Sezione Critica
    Zona del codice di manipolazione delle variabili condivise, non deve ~intrecciarsi~ co altre sezioni critiche
    - se un processo \(P_i\) sta eseguendo una sua sezione critica allora altri processi \(P_j\) non possono eseguire la propria
    - L'esecuzione della sezione critica di un \(P_i\) é mutualmente esclusivo con l'esecuzione delle sezioni critiche di altri \(P_j\)
      - anche se interrotto dalla scheduler nessun altro processo maniplante


**** Nel Sistema Operativo
    - accesso contemporaneo alla tabella dei file aperti
    - uso contemporaneo della fork
      + devono avere diversi PID
    In un sistema operativo il problema é risolto con una scelta
    - kernel con diritto di prelazione
      - un processo in kernel-mode puó essere interrotto da un altro processo
      - migliore per un sistema per applicazioni real-time
        + minore tempo di risposta
    - kernel senza diritto di prelazione
      - in kernel-mode un processo non puó essere interrotto
      - implementazione semplice: _disattivazione degli interrupt_
      - un solo processo alla volta puó accedere alle strutture dati dei kernel
        - accesso in modo esclusivo al codice della System Call

    Soluzione:
    - istruzioni macchina particolari
      + TestAndSet(v)
        #+begin_src C
boolean TestAndSet(boolean *lockvar){
    boolean tempvar = *lockvar;
    *lockvar = true;
    return tempvar;
}
        #+end_src
        Poi usata cosí
        #+begin_src C
boolean lock = false; // shared var
do{
    while(TestAndSet(&lock)); // while senza corpo
    //sezione critica            qui la variabile di lock == true
    lock = false;             // quando l'altro processo eseguirá il ciclo passerá il test
} while(true);
        #+end_src
        - In questo modo se un altro processo che testa lock resterá nel while in quanto _while(&lock) == while(true)_
        - l'_Attesa Limitata_ non é garantita
          - un processo potrebbe uscire dalla sezione critica e rientrarci nello stesso quanto di tempo
          - un meccanismo di aging non serva in quanto i processi entrano in esecuzione solamente che non riescono ad eseguire
          - puó essere implementata con una versione piú complessa
        - _Busy Waiting_:
          + il processo che tenta di accedere ad un lock fa busy-waiting
            - in quanto cicla in base ad una variabile che é modificabile sola da un altro processo
              + con un RR:
                - con \(N\) processi lo spreco di tempo di CPU sará \(N-1\) quanti di tempo
            - risolvibile con la disattivazione degli interrupt
              + perdita di controllo per un tempo arbitrario del OS
              + ci si deve fidare che il processo riabiliterá gli interrupt
      + Swap(\(v1\),\(v2\))

    Queste sono istruzioni macchina e quindi _atomiche_, non saranno mai interrotte a metá da un context switch
    I passi sono:
    - il processo tenta di accedere al lock
    - esegue la sezione critica
    - restituisce il lock

    ~NB~ La mutua esclusione in sistemi multi-core é piú complessa


***** Semafori
    Dijkstra - 1965
    Semaforo \(S\): variabile strutturata operabile tramite operazioni atomiche:
    - wait(S) ALIAS: P, down
      #+begin_src C
while S <= 0 do no-op;
S= S-1;
      #+end_src
    - signal(S) ALIAS: V, up
      #+begin_src C
S =S+1;
      #+end_src

      \(S\) é detta variabile semaforica, come se fosse un oggetto condiviso da tutti i processi per la sincronizzazione

    La variabile la chiameremo _mutex_ (mutual exclusion)
    #+begin_src C
P {
    do{
        wait(mutex);
        // sezione critica
        signal(mutex);
    } while(true);
}
    #+end_src

=sync=
    #+begin_src C
sync = 0;
P1{
    S1;
    signal(sync);
}
P2{
    wait(sync);
    S2;
}
    #+end_src

Questo tipo di semafori soffre ancora di busywaiting, sono chiamati _spinlock_
Soluzione implementata utilizzando System Call
- lista di semafori memorizzata nelle aree dati del kernel
- System Call
  + sleep() ALIAS: block()
    - toglie il processo dall'esecuzione
      + non viene inserito nella Ready Queue
  + wakeup()
    - rimette il processo in Ready Queue
- implementazione
  #+begin_src C
typedef struct{
    int valore; // se > 0 indica sezione critica libera
    struct process *waiting_list;
}semaforo;

wait(semaforo *S){
    S->valore--;
    if S->valore < 0 {
            // aggiunto processo a S in waiting_list
            sleep(); // il processo si é addormentato sul semaforo
    }
}

signal(semaforo *S) {
    S->valore++
    if S -> valore <= 0 {
            // togli un processo P da S -> waiting_list
            wakeup(P); // risvegliato P, va in Ready Queue
    }
}
  #+end_src

- NB
  - wait e signal sono _esse stesse sezioni critiche_ perché usano le stesse aree dati
    - risolvibile con una interruzione di interrupt o con busywaiting perché queste sono System Call e molto brevi
      + interruzione degli interrupt in multiprocessori non ovvio: sono disattivati solo su un particolare core

  - \(|mutex|\) = numero di processi addormentati
    - una S < 0 indica (in valore assoluto) il numero di processi addormentati su quel semaforo
      + se mutex = 1 allora \(P_1\) entra e \(mutex = 0\), context switch
      + un \(P_2\) testa mutex, \(mutex = -1\), \(P_2\) si addormenta

  - Utilizzabile un valore di semafori > 1 allora una risorsa é utilizzabile da 3 P contemporaneamente

  I semafori se utilizzati non correttamente possono provocare _deadlock_ e _starvation_
=======
>>>>>>> 74e75ebd8fe4cc2f57b733ba168b84613c120970

**** Esempi
    Problemi di sincronizzazione risolti utilizzando semafori

***** Produttori e Consumatori
    - buffer circolare[SIZE]
      + memoria condivisa da tutti i produttori e tutti i consumatori
    - semafori
      + full
      + empty
      + mutex
    - in
    - out

    #+name: Produttore
    #+begin_src C
while(true){
    produciItemInNextp();
    wait(empty);
    wait(mutex);
        buffer[in] = nextp;
        in = in++ mod SIZE;
    signal(mutex);
    signal(full);
}
    #+end_src
    #+name: Consumatore
    #+begin_src C
while(true){
    wait(full);
    wait(mutex); // in caso di piú consumatori e piú item nel buffer
        nextc = buffer[out];
        out = out++ mod SIZE;
    signal(mutex);
    signal(empty);
    consumaItemInNextc();
}
    #+end_src
***** Lettori e Scrittori
    Condivisione di un file tra molti processi
    - alcuni processi richiedono la sola lettura
      + possono essere paralleli
    - alcuni richiedono la scrittura
      + richiede la mutua esclusione di tutti i processi
****** Readers First
    Variabili:
    - condivise
      + semaforo mutex = 1
      + semaforo scrivi = 1
      + int numlettori = 0
    #+name: scrittore
    #+begin_src C
wait(scrivi);
scriviFile();
signal(scrivi);
    #+end_src
    #+name: lettore
    #+begin_src C
wait(mutex);
numlettori++;
if numlettori == 1
    wait(scrivi);
signal(mutex);
leggiFile();
wait(mutex);
numlettori--;
if numlettori == 0
    signal(scrivi);
signal(mutex);
    #+end_src

    E' garantita l'assenza di Deadlock e Starvation?
    - no
      - uno scrittore addormentato su scrivi dovra aspettare la terminazione di tutti i lettori, se continuano ad aggiungersi lettori ci sara' un Deadlock

****** Writers First

****** Fair

***** Cinque Filosofi
    - 1 tavolo circolare
      + 5 posti
      + 5 piatti
      + 5 bacchette condivise
        - 2 necessarie per mangiare
    Ogni risorsa e' associata ad un semafori in un array
    #+begin_src C
do{
    wait(bacchetta[i]) // context switch qui causa Deadlock
                       // Attesa Circolare
    wait(bacchetta[i+1 mod 5]);
        mangia();
    signal(bacchetta[i]);
    signal(bacchetta[i+1 mod 5]);
        pensa();
}while(true);
    #+end_src

** Deadlock
    Programma A aspetta informazione dal Programma B che aspetta...
    Il deadlock non é affrontato dagli OS, deve essere gestito dall'OS
    - se uno dei dui processi cede il passo risolviamo la deadlock ma non la =starvation=

    _Modello del Sistema_
    - Tipi di risorse R
      + ognuna formata da istanze indistinguibili tra loro
    - Processi P
      + hanno bisogno di alcune istanze di R
    In una situazione di attesa circolare le risorse possono rimanere bloccate, quindi questo é un problema di tutto il sistema
    L'OS potrebbe implementare delle soluzioni con adeguate rappresentazione del _grafo di assegnazione delle risorse_
    - se si verifica un ciclo in questo grafo é chiara la situazione di deadlock e allora viene risolta
      - causa un sottoutilizzo delle risorse (poiché non evita i deadlock di per se)
    - oppure si potrebbe evitare i deadlock verificando prima di concedere una risorsa che questa non porti ad una attesa circolare
      - troppo dispendioso dal punto di vista della computazione per l'OS

* Gestione Memoria

** Centrale
Bisogna decidere come spartire lo spazio di memorizzazione tra i processi attivi
- _l'immagine_ di un processo inattivo nei prossimi cicli di CPU puo essere spostato su hard disk
- quando un processo rientra in RAM occupera' spazio prima occupato
Questo e' lo ~swap~
*** Binding
Associazione degli indirizzi
- ad ogni variabile di un programma va associato un indirizzo che ne contiene il valore
- alle istruzioni di salto va associato l'indirizzo di salto in caso questo avvenga

_In fase di Compilazione_
- generato codice assoluto o _statico_
- il compilatore deve conoscere l'idirizzo della cella a partire dalla quale verra' cariato il programma per poter portare a termine il binding
- se il processo e' spostato in memoria secondaria
  + dovra essere messo allo stesso indirizzo
  + o ricompilato ad un nuovo indirizzo

_In fase di caricamento in RAM_
- generato codice _staticamente rilocabile_
- il compilatore associa indirizzi relativi all'inizio del programma (indirizzo 0)
- indirizzi assoluti generati in fase di caricamento
- se il processo e' spostato in memoria secondaria
  + piu' efficiente in quanto e' in fase di caricamento che vengono risolti i riferimenti

_In fase di esecuzione_ aka ~binding dinamico degli indirizzi~
- generato codice diamicamente rilocabile
- il codice utilizza sempre e solo indirizzi relativi
  + questi sono risolti solo al momento dell'esecuzione dell'istruzione in particolare
- necessita un supporto hardware per non perdere efficienza
  + registro di rilocazione
    - indirizzo di partenza in cui e' caricato il programma in esecuzione
  + MMU
    - risolve gli indirizzi in assoluti
- cosi non ci son
 
**** Librerie
2 tipi:
- Statiche
  + Associata dal compilatore o dal loader e collegata al programma in memoria
    - anche se la subroutine non e' utilizzata viene memorizzata in memoria principale
  + Ogni programma dovra' avere una copia del codice della libreria in quanto direttamente associati
  + provoca dublicazione del codice in memoria
- Dinamiche
  + caricate a runtime
    - solo dopo una specifica invocazione in corso di esecuzione il Sistema Operativo interrompe e carica in RAM il necessario prima di ridare il controllo al programma
  + diversi programmi condividono la stessa porzione di codice in RAM se chiamano la stessa libreria
    - viene carica un sola volta eliminando la dublicazione di codice
  + una nuova versione della libreria e' automaticamente caricata dal programma, non ci sara' bisogno di ricompilare i moduli per compilare la nuova libreria

*** Spazi degli indirizzi
:PROPERTIES:
:ID:       e20e286c-f8ae-48a6-9447-a94f3588f4cd
:END:
tag: [[file:20201102165014-ram.org][Memorie]]

Ogni indirizzo di un programma in un sistema allocato dinamicamente sará sempre compreso tra $0$ e un $max$
- Questo spazio e' chiamato spazio degli indirizzi o _spazio di indirizzamento logico_
- Gli indirizzi sono definiti =logici= o =virtuali=
  + questi sono convertiti in indirizzi =fisici= dal registro di rilocazione
    - somma del registro e del registro logico a livello hardware
    - indicano una determinata cella in RAM
- Analogamente c'e' uno _spazio di indirizzamento fisico_
  - da $r+0$ a $r+max$

=NB=: il numero di bit per la memorizzazione degli indirizzi logici puo essere diverso da quello per la memorizzazione degli indirizzi fisici
- allora lo spazio degli indirizzi logici sara' piu' piccolo in quella architettura
  + un programma avra' un limite di grandezza e memorizzazione
Questo e' il caso piu' frequente, infatti in caso di indirizzi fisici a 64 bit, questi sono troppi in casi normali:
- sono indirizzabili $2^{40} B$ ovvero $1 TB$ con un indirizzamento di 40 bit
Solitamente vale questa relazione:
\(|RAM|_{effettiva}<|RAM|_{max}<<|PhisSpace|<|VirtSpace|\)
- Questo e' possibile grazie la memoria virtuale

*** Tecniche di Gestione della memoria
**** Swapping
Salvataggio in memoria secondaria di un =immagine= del processo non in esecuzione (~swap out~) e ricaricarla successivamente (~swap in~)
- =area di swap=
  + area di harddisk ad uso esclusivo del OS
- l'operazione di =swap in= posiziona il processo in una diversa area di MP
  + viene aggiornato il =registro di rilocazione=
- grande ~overhead~ causato dallo spostamento su disco
  + tecnica abbandonata
    - ora sostituita dalla memoria virtuale
      + e' spostato solo una parte del programma
**** Allocazione contigua a partizioni multiple fisse
NB: tecnica utilizzata dal IBM OS/360
Memoria Principale suddivisa in 2 _partizioni_
- OS
- Processi Utente
  + occupata solo un processo nei casi piu' semplici
  + =registro limite= protegge la memoria primaria riservata al OS
  + un registro di rilocazione permettera' la risoluzione del indirizzo fisico
  + Le partizioni sono di dimensione fissa
    - non necessariamente uguali
    - ogni processo puo' accedere solo alla sua porzione
      + registri di rilocazione a ggiornati ad ogni context switch
      + registro limite aggiornato con la dimensione della partizione
_Limiti_
- Questa tecnica limita il grado di ~multiprogrammazione~ al numero di partizioni previste
- Inoltre si verifica ~frammentazione~
  + interna perche' nessun processo occupera' esattamente la partizione assegnata
  + esterna perche' le frammentazioni interne si sommano per uno spreco globale
**** Allocazione contigua a partizioni multiple variabile
_Partizioni_ misurate sulla grandezza dei processi
- Questo crea buchi di RAM sempre piu' piccoli e numerosi tra i processi durante l'evoluzione dell'esecuzione
  + sara' sempre piu' difficile utilizzare lo spazio in quanto troppo frammentato
_Scelta della partizione_
- First Fit
  + utilizzata prima partizione abbastanza grande
- Best Fit
  + utilizza piu' piccola partizione abbastanza grande
- Worst Fit
  + utilizza la partizione piu' grande
_Limiti_
- Frammentazione esterna aumenta con il tempo
- Frammentazione interna in quanto costa troppo tenere traccia dei buchi tra i processi e questi rimarranno nascosti
_Soluzione_
- Rilocazione dei processi in maniera contigua
  + quindi sara' necessaria una implementazione dinamicamente rilocabile
  + verso il basso o l'alto
- Compattamento
  + creazione di un unica area libera di memoria
**** Paginazione
Area di memoria allocata da un processo suddivisa in pezzi _non contigui_
- ~Frame~ o ~Pagine Fisiche~
  + pezzi di dimensione fissa in cui e' divisa la Memoria Principale aka spazio di indirizzamento fisico (potenze di 2)
    - a differenza dalla =segmentazione=
- ~Pagine~
  + pezzi di dimensione identica ai frame in cui e' suddiviso lo spazio di indirizzamento logico

L'OS carica $x$ pagine cercando $x$ frame liberi, il cui ordine e posizione non e' importante

_Architettura di Paginazione_
- =Page-Table=
  + array con cui tiene traccia degli indici di pagine e frame
- Traduzione Indirizzi Logici
  + questo implementa la =traduzione= tra indirizzi paginati logici a indirizzi paginati fisici
    - pagina $p$ indice della tabella per ottenere il frame $f$ che lo contiene
      + nella entry $p$ si trova l'indirizzo di partenza del frame puntato
    - offset $d$ (displacement) utilizzato a partire dall'indirizzo fisico del frame $f$
      + questo e' sommato all'indirizzo puntato da $p$ nella tabella delle pagine per ricavare l'indirizzo fisico
- Elenco dei frame liberi
  + aggiornato ogni volta che e' necessario
   
_Indirizzi Logici_ reimplementati
- non piu' lineari
- nuova implementazione
  + coppia di valori =(page, offset)=
    - numero della pagina da indirizzare
    - offset rispetto all'inizio della pagina


L'hardware impone alcune dimensioni
- bit indirizzo logico - $m$
- dimensione del frame - $2^{n}$
  + $n$ bit di offset
  + $m-n$ bit per indirizzare le pagine
- Spazio di Indirizzamento Logico
  + $2^{m-n}\times 2^{n}$
In questo caso l'OS deve adeguarsi al hardware cui e' posto, cosi' facendo la sequenza lineare di valori degli indirizzi fisici e' interpretata come coppia di valori
- bit piu' significativi come numero del frame
- bit meno significativi come offset $d$
Questo e' implementato in modo piu' semplice utilizzando come grandezze di indirizzamento potenze di 2
- in questo modo:
  + non sara' necessario memorizzare l'indirizzo di partenza del _frame_ ma solo il suo _numero_
  + non sara' necessario operare una somma tra indirizzo e offset ma solamente una _concatenazione_ (piu' veloce)
**** Paginazione a piu' livelli

** Virtuale

* Gestione Memoria di massa

** Rigidi

** RAID

** File System

*** Interfaccia

*** Realizzazione
* Laboratorio

** [[file:20200929150429-c.org][C]]

** [[file:20200929150510-unix.org][Unix]]
